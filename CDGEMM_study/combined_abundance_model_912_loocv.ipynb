{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YH20TaYMfOPx"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import sys\n","import os\n","if not sys.warnoptions:\n","    warnings.simplefilter(\"ignore\")\n","    os.environ[\"PYTHONWARNINGS\"] = \"ignore::UserWarning\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5mHH-frLYN_I"},"outputs":[],"source":["# Load packages\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import re\n","from collections import Counter, defaultdict\n","from joblib import Parallel, delayed\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import SelectKBest, f_classif, RFE\n","from sklearn.linear_model import LassoCV, LogisticRegression, LogisticRegressionCV, ElasticNetCV, ElasticNet\n","from sklearn.metrics import f1_score, roc_auc_score\n","from sklearn.model_selection import LeaveOneOut, KFold, GridSearchCV, StratifiedKFold\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","import statistics\n","import xgboost as xgb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"executionInfo":{"elapsed":5126,"status":"ok","timestamp":1716746521218,"user":{"displayName":"ZHIQI ZHANG","userId":"11425140851942185431"},"user_tz":240},"id":"zO7a90AvYqwL","outputId":"03b794b3-887f-4421-eda9-22048738a493"},"outputs":[],"source":["# Load dataset\n","species_data = pd.read_excel('species_abundance_merged_2024-08-13.xlsx')\n","pathway_data = pd.read_excel('pathway_abundance_merged_2024-08-21.xlsx')\n","\n","# List of columns to merge on\n","merge_columns = ['SampleID', 'Subject', 'Subject_number', 'timepoint_numeric', 'Diagnosis', 'CD_onset', 'Relative_timepoint', 'Country']\n","\n","# Perform the merge\n","combined_data = pd.merge(species_data, pathway_data, on=merge_columns, how='inner')\n","combined_data"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Exclude subjects with a CD onset of 12 months\n","excluded_subjects = [23, 31]\n","combined_data = combined_data[~combined_data['Subject_number'].isin(excluded_subjects)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to apply abundance and prevalence thresholds\n","def filter_features(data, abundance_threshold = 0.001, prevalence_threshold = 0.1):\n","    initial_features_count = data.shape[1] - 8\n","    sample_count = data.shape[0]\n","    \n","    # Calculate prevalence threshold\n","    min_prevalent_samples = int(prevalence_threshold * sample_count)\n","\n","    # Filter features based on the thresholds\n","    features_columns = data.columns.difference(['SampleID', 'Subject', 'Subject_number', 'timepoint_numeric', 'Diagnosis', 'CD_onset', 'Relative_timepoint', 'Country'])\n","    features_data = data[features_columns]\n","    \n","    # Calculate the abundance and prevalence for each feature\n","    features_above_threshold = (features_data >= abundance_threshold).sum(axis=0) >= min_prevalent_samples\n","    filtered_features = features_columns[features_above_threshold]\n","    \n","    # Filter the data to keep only the selected species\n","    filtered_data = data[['SampleID', 'Subject', 'Subject_number', 'timepoint_numeric', 'Diagnosis', 'CD_onset', 'Relative_timepoint', 'Country'] + filtered_features.tolist()]\n","\n","    final_features_count = len(filtered_features)\n","    print(f\"Initial number of features: {initial_features_count}\")\n","    print(f\"Number of features after filtering: {final_features_count}\")\n","    \n","    return filtered_data\n","\n","# Filter the data\n","combined_data_filtered = filter_features(combined_data)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Divide subjects into early onset (â‰¤ 30 months) and late onset (> 30 months)\n","early_onset_subjects = [9, 20, 27, 29, 30, 35, 10, 21, 22, 36, 5, 13, 18, 25, 34]\n","\n","late_onset_subjects = [11, 24, 3, 12, 15, 17, 28, 32, 16, 1, 4, 6, 8, 14, 19, 2, 7]\n","\n","# Filter data for each group\n","early_onset_data = combined_data_filtered[(combined_data_filtered['Subject_number'].isin(early_onset_subjects)) & (combined_data_filtered['timepoint_numeric'] < 18)]\n","late_onset_data = combined_data_filtered[(combined_data_filtered['Subject_number'].isin(late_onset_subjects)) & (combined_data_filtered['timepoint_numeric'] < 36)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","# Define selected features for each time point\n","features_timepoint_12 = [\n","    'Phocaeicola_dorei', 'Bifidobacterium_pseudocatenulatum', 'Roseburia_inulinivorans', 'Bifidobacterium_dentium', \n","    'Megasphaera_micronuciformis', 'Roseburia_faecis', 'Bacteroides_stercoris', 'Streptococcus_thermophilus', \n","    'P164-PWY: purine nucleobases degradation I (anaerobic)', 'COA-PWY-1: superpathway of coenzyme A biosynthesis III (mammals)', \n","    'ASPASN-PWY: superpathway of L-aspartate and L-asparagine biosynthesis', 'PWY-5121: superpathway of geranylgeranyl diphosphate biosynthesis II (via MEP)'\n","]\n","\n","features_timepoint_15 = [\n","    'Intestinibacter_bartlettii', 'Bifidobacterium_pseudocatenulatum', 'Anaerostipes_hadrus', 'Ruminococcus_gnavus', 'Escherichia_coli', \n","    'Clostridium_SGB6179', 'Mediterraneibacter_faecis', 'GLYOXYLATE-BYPASS: glyoxylate cycle', 'COMPLETE-ARO-PWY: superpathway of aromatic amino acid biosynthesis', \n","    'FASYN-ELONG-PWY: fatty acid elongation -- saturated', 'HEMESYN2-PWY: heme b biosynthesis II (oxygen-independent)', 'CENTFERM-PWY: pyruvate fermentation to butanoate'\n","]\n","\n","# Define a function to evaluate combinations of feature selectors and models\n","def evaluate_models(data, max_timepoint):\n","    results = {}\n","\n","    # Define a function to process each time point independently\n","    def process_time_point(time_point):\n","        print(f\"Processing time point: {time_point}\")\n","\n","        # Select appropriate features based on the time point\n","        if time_point == 12:\n","            selected_features = features_timepoint_12\n","        elif time_point == 15:\n","            selected_features = features_timepoint_15\n","        else:\n","            print(f\"No predefined features for time point {time_point}.\")\n","            return time_point, None\n","\n","        # Filter data for the current time point and extract selected features\n","        current_data = data[data['timepoint_numeric'] == time_point]\n","        X = current_data[selected_features] # Feature matrix\n","        y = current_data['Diagnosis'] # Labels\n","\n","        # Ensure there are enough samples to perform LOOCV\n","        if len(y) < 2:\n","            print(f\"Skipping time point {time_point} due to insufficient samples.\")\n","            return time_point, None\n","\n","        # Initialize Leave-One-Out cross-validation\n","        loo = LeaveOneOut()\n","        best_overall_score = 0\n","        best_overall_setup = {}\n","\n","        # Define a function to process each feature selector and model combination\n","        def process_combination(feature_selector_name, ml_model_name):\n","            all_selected_features = []\n","            all_importances = []\n","\n","            # Loop through the training/test splits generated by LOOCV\n","            for train_index, test_index in loo.split(X):\n","                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                # Perform feature selection based on the specified selector\n","                if feature_selector_name == 'LASSO':\n","                    feature_selector = LassoCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30)).fit(X_train, y_train)\n","                else:\n","                    feature_selector = ElasticNetCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7).fit(X_train, y_train)\n","\n","                # Select features with non-zero coefficients\n","                selected_features = X_train.columns[feature_selector.coef_ != 0]\n","                selected_features = selected_features[:min(len(selected_features), int(0.8 * len(y_train)))]\n","\n","                # If no features are selected, skip this iteration\n","                if len(selected_features) == 0:\n","                    continue\n","\n","                # Select the relevant features from the training set\n","                X_train_selected = X_train[selected_features]\n","\n","                # Perform logistic regression for ranking the selected features based on importance\n","                logistic = LogisticRegression(max_iter=10000, random_state=42, solver='liblinear').fit(X_train_selected, y_train)\n","                importances = abs(logistic.coef_[0])\n","                ranked_features = sorted(zip(selected_features, importances), key=lambda x: x[1], reverse=True)\n","\n","                # Store selected features and their importance\n","                all_selected_features.extend([f[0] for f in ranked_features])\n","                all_importances.extend([f[1] for f in ranked_features])\n","\n","            # If no features were selected across all folds, return None\n","            if not all_selected_features:\n","                return None\n","\n","            # Aggregate selected features across all folds\n","            unique_features = list(set(all_selected_features))\n","            frequency = Counter(all_selected_features)\n","            avg_importance = {feature: np.mean([imp for feat, imp in zip(all_selected_features, all_importances) if feat == feature])\n","                              for feature in unique_features}\n","\n","            # Calculate a composite score for each feature based on frequency and importance\n","            composite_scores = {feature: 0.5 * (frequency[feature] / loo.get_n_splits(X)) + 0.5 * (avg_importance[feature] / sum(avg_importance.values()))\n","                                for feature in unique_features}\n","            sorted_features = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","            # Evaluate different feature subsets with varying thresholds\n","            best_overall_performance = 0\n","            best_overall_setup = {}\n","            best_percentage = 0\n","            thresholds = np.linspace(0.05, 0.95, 19)\n","\n","            for i in range(1, min(len(sorted_features), int(0.8 * len(y))) + 1):\n","                selected_features = [feature[0] for feature in sorted_features[:i]]\n","                best_performance_for_features = 0\n","                best_threshold_for_features = None\n","\n","                for threshold in thresholds:\n","                    fold_f1_scores = []\n","\n","                    # Perform LOOCV prediction with the selected features and model\n","                    for train_index, test_index in loo.split(X):\n","                        X_train, X_test = X.iloc[train_index][selected_features], X.iloc[test_index][selected_features]\n","                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                        # Use the appropriate model for prediction\n","                        if ml_model_name == 'ElasticNet':\n","                            model = ElasticNetCV(cv=5, max_iter=10000, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7)\n","                        elif ml_model_name == 'RandomForest':\n","                            model = RandomForestClassifier(n_estimators=300, random_state=42)\n","                        else:\n","                            model = xgb.XGBClassifier(n_estimators=500, learning_rate=0.1, eval_metric='logloss', random_state=42)\n","\n","                        # Fit the model, make predictions and compute F1 score for the current fold\n","                        model.fit(X_train, y_train)\n","                        test_prediction = (model.predict(X_test) >= threshold).astype(int) if ml_model_name == 'ElasticNet' else (model.predict_proba(X_test)[:, 1] >= threshold).astype(int)\n","                        f1_score_current = f1_score(y_test, test_prediction, average='macro')\n","                        fold_f1_scores.append(f1_score_current)\n","\n","                    # Calculate the average F1 score for the current threshold\n","                    f1_score_avg = np.mean(fold_f1_scores)\n","\n","                    # Record the best performance and threshold for the features\n","                    if f1_score_avg > best_performance_for_features:\n","                        best_performance_for_features = f1_score_avg\n","                        best_threshold_for_features = threshold\n","\n","                # Update the best overall performance if it improves\n","                if best_performance_for_features > best_overall_performance:\n","                    best_overall_performance = best_performance_for_features\n","                    best_overall_setup = {\n","                        'features': selected_features,\n","                        'threshold': best_threshold_for_features,\n","                        'performance': best_performance_for_features,\n","                        'feature_selection_method': feature_selector_name,\n","                        'ml_model': ml_model_name\n","                    }\n","\n","            return {\n","                'feature_selection_method': best_overall_setup['feature_selection_method'],\n","                'ml_model': best_overall_setup['ml_model'],\n","                'best_features': best_overall_setup['features'],\n","                'features_length': len(best_overall_setup['features']),\n","                'best_threshold': best_overall_setup['threshold'],\n","                'best_performance': best_overall_setup['performance']\n","            }\n","\n","        # Process combinations of feature selection and prediction models\n","        combinations = [('LASSO', 'ElasticNet'), ('ElasticNet', 'ElasticNet')]\n","        results_per_combination = [process_combination(fs, ml) for fs, ml in combinations]\n","        best_combination = max(results_per_combination, key=lambda x: x['best_performance'] if x is not None else 0)\n","\n","        return time_point, best_combination\n","\n","    # Process time points within the specified max_timepoint\n","    time_points = np.sort(data[data['timepoint_numeric'] < max_timepoint]['timepoint_numeric'].unique())\n","    results_parallel = Parallel(n_jobs=-1)(delayed(process_time_point)(tp) for tp in time_points)\n","    results = {tp: result for tp, result in results_parallel if result is not None}\n","\n","    return results\n","\n","# Set the max timepoint for early onset groups\n","early_onset_max_timepoint = 18\n","\n","# Evaluate models for early onset group\n","print(\"Evaluating Early Onset Group\")\n","results_early_onset = evaluate_models(early_onset_data, early_onset_max_timepoint)\n","\n","# Print results for early onset group\n","print(\"Results for Early Onset Group:\")\n","for time_point, res in results_early_onset.items():\n","    if res is not None:\n","        print(f\"Time Point: {time_point}\")\n","        print(f\"  Feature Selection Method: {res['feature_selection_method']}\")\n","        print(f\"  Machine Learning Model: {res['ml_model']}\")\n","        print(f\"  Best F1 Score: {res['best_performance']}\")\n","        print(f\"  Best Threshold: {res['best_threshold']}\")\n","        print(f\"  Features Used: {res['best_features']}\")\n","        print(f\"  Features Length: {res['features_length']}\")\n","        print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","# Define selected features for each time point\n","features_timepoint_12 = [\n","    'Phocaeicola_dorei', 'Bifidobacterium_pseudocatenulatum', 'Roseburia_inulinivorans', 'Bifidobacterium_dentium', \n","    'Megasphaera_micronuciformis', 'Roseburia_faecis', 'Bacteroides_stercoris', 'Streptococcus_thermophilus', \n","    'P164-PWY: purine nucleobases degradation I (anaerobic)', 'COA-PWY-1: superpathway of coenzyme A biosynthesis III (mammals)', \n","    'ASPASN-PWY: superpathway of L-aspartate and L-asparagine biosynthesis', 'PWY-5121: superpathway of geranylgeranyl diphosphate biosynthesis II (via MEP)'\n","]\n","\n","features_timepoint_15 = [\n","    'Intestinibacter_bartlettii', 'Bifidobacterium_pseudocatenulatum', 'Anaerostipes_hadrus', 'Ruminococcus_gnavus', 'Escherichia_coli', \n","    'Clostridium_SGB6179', 'Mediterraneibacter_faecis', 'GLYOXYLATE-BYPASS: glyoxylate cycle', 'COMPLETE-ARO-PWY: superpathway of aromatic amino acid biosynthesis', \n","    'FASYN-ELONG-PWY: fatty acid elongation -- saturated', 'HEMESYN2-PWY: heme b biosynthesis II (oxygen-independent)', 'CENTFERM-PWY: pyruvate fermentation to butanoate'\n","]\n","\n","# Define a function to evaluate combinations of feature selectors and models\n","def evaluate_models(data, max_timepoint):\n","    results = {}\n","\n","    # Define a function to process each time point independently\n","    def process_time_point(time_point):\n","        print(f\"Processing time point: {time_point}\")\n","\n","        # Select appropriate features based on the time point\n","        if time_point == 12:\n","            selected_features = features_timepoint_12\n","        elif time_point == 15:\n","            selected_features = features_timepoint_15\n","        else:\n","            print(f\"No predefined features for time point {time_point}.\")\n","            return time_point, None\n","\n","        # Filter data for the current time point and extract selected features\n","        current_data = data[data['timepoint_numeric'] == time_point]\n","        X = current_data[selected_features] # Feature matrix\n","        y = current_data['Diagnosis'] # Labels\n","\n","        # Ensure there are enough samples to perform LOOCV\n","        if len(y) < 2:\n","            print(f\"Skipping time point {time_point} due to insufficient samples.\")\n","            return time_point, None\n","\n","        # Initialize Leave-One-Out cross-validation\n","        loo = LeaveOneOut()\n","        best_overall_score = 0\n","        best_overall_setup = {}\n","\n","        # Define a function to process each feature selector and model combination\n","        def process_combination(feature_selector_name, ml_model_name):\n","            all_selected_features = []\n","            all_importances = []\n","\n","            # Loop through the training/test splits generated by LOOCV\n","            for train_index, test_index in loo.split(X):\n","                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                # Perform feature selection based on the specified selector\n","                if feature_selector_name == 'LASSO':\n","                    feature_selector = LassoCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30)).fit(X_train, y_train)\n","                else:\n","                    feature_selector = ElasticNetCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7).fit(X_train, y_train)\n","\n","                # Select features with non-zero coefficients\n","                selected_features = X_train.columns[feature_selector.coef_ != 0]\n","                selected_features = selected_features[:min(len(selected_features), int(0.8 * len(y_train)))]\n","\n","                # If no features are selected, skip this iteration\n","                if len(selected_features) == 0:\n","                    continue\n","\n","                # Select the relevant features from the training set\n","                X_train_selected = X_train[selected_features]\n","\n","                # Perform logistic regression for ranking the selected features based on importance\n","                logistic = LogisticRegression(max_iter=10000, random_state=42, solver='liblinear').fit(X_train_selected, y_train)\n","                importances = abs(logistic.coef_[0])\n","                ranked_features = sorted(zip(selected_features, importances), key=lambda x: x[1], reverse=True)\n","\n","                # Store selected features and their importance\n","                all_selected_features.extend([f[0] for f in ranked_features])\n","                all_importances.extend([f[1] for f in ranked_features])\n","\n","            # If no features were selected across all folds, return None\n","            if not all_selected_features:\n","                return None\n","\n","            # Aggregate selected features across all folds\n","            unique_features = list(set(all_selected_features))\n","            frequency = Counter(all_selected_features)\n","            avg_importance = {feature: np.mean([imp for feat, imp in zip(all_selected_features, all_importances) if feat == feature])\n","                              for feature in unique_features}\n","\n","            # Calculate a composite score for each feature based on frequency and importance\n","            composite_scores = {feature: 0.5 * (frequency[feature] / loo.get_n_splits(X)) + 0.5 * (avg_importance[feature] / sum(avg_importance.values()))\n","                                for feature in unique_features}\n","            sorted_features = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","            # Evaluate different feature subsets with varying thresholds\n","            best_overall_performance = 0\n","            best_overall_setup = {}\n","            best_percentage = 0\n","            thresholds = np.linspace(0.05, 0.95, 19)\n","\n","            for i in range(1, min(len(sorted_features), int(0.8 * len(y))) + 1):\n","                selected_features = [feature[0] for feature in sorted_features[:i]]\n","                best_performance_for_features = 0\n","                best_threshold_for_features = None\n","\n","                for threshold in thresholds:\n","                    fold_f1_scores = []\n","\n","                    # Perform LOOCV prediction with the selected features and model\n","                    for train_index, test_index in loo.split(X):\n","                        X_train, X_test = X.iloc[train_index][selected_features], X.iloc[test_index][selected_features]\n","                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                        # Use the appropriate model for prediction\n","                        if ml_model_name == 'ElasticNet':\n","                            model = ElasticNetCV(cv=5, max_iter=10000, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7)\n","                        elif ml_model_name == 'RandomForest':\n","                            model = RandomForestClassifier(n_estimators=300, random_state=42)\n","                        else:\n","                            model = xgb.XGBClassifier(n_estimators=500, learning_rate=0.1, eval_metric='logloss', random_state=42)\n","\n","                        # Fit the model, make predictions and compute F1 score for the current fold\n","                        model.fit(X_train, y_train)\n","                        test_prediction = (model.predict(X_test) >= threshold).astype(int) if ml_model_name == 'ElasticNet' else (model.predict_proba(X_test)[:, 1] >= threshold).astype(int)\n","                        f1_score_current = f1_score(y_test, test_prediction, average='macro')\n","                        fold_f1_scores.append(f1_score_current)\n","\n","                    # Calculate the average F1 score for the current threshold\n","                    f1_score_avg = np.mean(fold_f1_scores)\n","\n","                    # Record the best performance and threshold for the features\n","                    if f1_score_avg > best_performance_for_features:\n","                        best_performance_for_features = f1_score_avg\n","                        best_threshold_for_features = threshold\n","\n","                # Update the best overall performance if it improves\n","                if best_performance_for_features > best_overall_performance:\n","                    best_overall_performance = best_performance_for_features\n","                    best_overall_setup = {\n","                        'features': selected_features,\n","                        'threshold': best_threshold_for_features,\n","                        'performance': best_performance_for_features,\n","                        'feature_selection_method': feature_selector_name,\n","                        'ml_model': ml_model_name\n","                    }\n","\n","            return {\n","                'feature_selection_method': best_overall_setup['feature_selection_method'],\n","                'ml_model': best_overall_setup['ml_model'],\n","                'best_features': best_overall_setup['features'],\n","                'features_length': len(best_overall_setup['features']),\n","                'best_threshold': best_overall_setup['threshold'],\n","                'best_performance': best_overall_setup['performance']\n","            }\n","\n","        # Process combinations of feature selection and prediction models\n","        combinations = [('LASSO', 'ElasticNet'), ('ElasticNet', 'ElasticNet'), \n","                        ('LASSO', 'RandomForest'), ('ElasticNet', 'RandomForest'), \n","                        ('LASSO', 'XGBoost'), ('ElasticNet', 'XGBoost')]\n","        results_per_combination = [process_combination(fs, ml) for fs, ml in combinations]\n","        best_combination = max(results_per_combination, key=lambda x: x['best_performance'] if x is not None else 0)\n","\n","        return time_point, best_combination\n","\n","    # Process time points within the specified max_timepoint\n","    time_points = np.sort(data[data['timepoint_numeric'] < max_timepoint]['timepoint_numeric'].unique())\n","    results_parallel = Parallel(n_jobs=-1)(delayed(process_time_point)(tp) for tp in time_points)\n","    results = {tp: result for tp, result in results_parallel if result is not None}\n","\n","    return results\n","\n","# Set the max timepoint for early onset groups\n","early_onset_max_timepoint = 18\n","\n","# Evaluate models for early onset group\n","print(\"Evaluating Early Onset Group\")\n","results_early_onset = evaluate_models(early_onset_data, early_onset_max_timepoint)\n","\n","# Print results for early onset group\n","print(\"Results for Early Onset Group:\")\n","for time_point, res in results_early_onset.items():\n","    if res is not None:\n","        print(f\"Time Point: {time_point}\")\n","        print(f\"  Feature Selection Method: {res['feature_selection_method']}\")\n","        print(f\"  Machine Learning Model: {res['ml_model']}\")\n","        print(f\"  Best F1 Score: {res['best_performance']}\")\n","        print(f\"  Best Threshold: {res['best_threshold']}\")\n","        print(f\"  Features Used: {res['best_features']}\")\n","        print(f\"  Features Length: {res['features_length']}\")\n","        print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","# Define selected features for each time point\n","features_timepoint_12 = [\n","    'Veillonella_dispar', 'Lachnospira_pectinoschiza', 'Phocaeicola_dorei', 'Gemmiger_formicilis', 'Bifidobacterium_breve', 'Bifidobacterium_dentium', \n","    'Enterococcus_faecium', 'Roseburia_inulinivorans', 'Escherichia_coli', 'Parabacteroides_merdae', 'Enterococcus_avium', 'Bifidobacterium_pseudocatenulatum', \n","    'Alistipes_putredinis', 'Faecalibacterium_sp_HTFF', 'Lacticaseibacillus_rhamnosus', 'PWY-5005: biotin biosynthesis II', 'PWY-5838: superpathway of menaquinol-8 biosynthesis I'\n","]\n","\n","features_timepoint_15 = [\n","    'Veillonella_ratti', 'Longicatena_caecimuris', 'Erysipelatoclostridium_ramosum', 'Anaerobutyricum_soehngenii', 'Roseburia_intestinalis', \n","    'Bifidobacterium_pseudocatenulatum', 'Sutterella_wadsworthensis', 'Phocaeicola_dorei', 'Roseburia_faecis', 'Bacteroides_uniformis', 'Faecalibacterium_sp_HTFF', \n","    'HISDEG-PWY: L-histidine degradation I', 'P23-PWY: reductive TCA cycle I', 'ARGININE-SYN4-PWY: L-ornithine biosynthesis II', \n","    'CENTFERM-PWY: pyruvate fermentation to butanoate', 'P621-PWY: nylon-6 oligomer degradation', 'P562-PWY: myo-inositol degradation I', \n","    'P461-PWY: hexitol fermentation to lactate, formate, ethanol and acetate', 'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', \n","    'COLANSYN-PWY: colanic acid building blocks biosynthesis', 'NAGLIPASYN-PWY: lipid IVA biosynthesis (E. coli)', 'LIPA-CORESYN-PWY: lipid A-core biosynthesis (E. coli K-12)', \n","    'LPSSYN-PWY: superpathway of lipopolysaccharide biosynthesis', 'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)', \n","    'PROPFERM-PWY: superpathway of L-alanine fermentation (Stickland reaction)', 'P161-PWY: acetylene degradation (anaerobic)', 'GALACTITOLCAT-PWY: galactitol degradation', \n","    'GLCMANNANAUT-PWY: superpathway of N-acetylglucosamine, N-acetylmannosamine and N-acetylneuraminate degradation', \n","    'PWY-1861: formaldehyde assimilation II (assimilatory RuMP Cycle)', 'METHGLYUT-PWY: superpathway of methylglyoxal degradation', 'CITRULBIO-PWY: L-citrulline biosynthesis', \n","    'DENITRIFICATION-PWY: nitrate reduction I (denitrification)'\n","]\n","features_timepoint_18 = [\n","    'Streptococcus_thermophilus', 'Lactococcus_lactis', 'Bifidobacterium_adolescentis', 'GGB51647_SGB4348', 'Fusicatenibacter_saccharivorans', 'Phocaeicola_dorei', \n","    'Streptococcus_salivarius', 'Faecalibacterium_sp_HTFF', 'Alistipes_putredinis', 'Anaerobutyricum_hallii', 'Gemmiger_formicilis', 'Bifidobacterium_longum', \n","    'Blautia_caecimuris', 'GLUDEG-I-PWY: GABA shunt', 'PWY-5861: superpathway of demethylmenaquinol-8 biosynthesis I', 'P42-PWY: incomplete reductive TCA cycle', \n","    'ARG+POLYAMINE-SYN: superpathway of arginine and polyamine biosynthesis', 'DENOVOPURINE2-PWY: superpathway of purine nucleotides de novo biosynthesis II', \n","    'PWY-5022: 4-aminobutanoate degradation V', 'P621-PWY: nylon-6 oligomer degradation', 'PWY-561: superpathway of glyoxylate cycle and fatty acid degradation', \n","    'PWY-5918: superpathway of heme b biosynthesis from glutamate', 'GLYCOLYSIS-E-D: superpathway of glycolysis and the Entner-Doudoroff pathway', \n","    'PWY-5005: biotin biosynthesis II', 'PWY-5994: palmitate biosynthesis (type I fatty acid synthase)', 'PWY-241: C4 photosynthetic carbon assimilation cycle, NADP-ME type', \n","    'HEME-BIOSYNTHESIS-II: heme b biosynthesis I (aerobic)', 'CITRULBIO-PWY: L-citrulline biosynthesis', 'PWY-5686: UMP biosynthesis I', \n","    'BIOTIN-BIOSYNTHESIS-PWY: biotin biosynthesis I'\n","]\n","\n","features_timepoint_21 = [\n","    'Alistipes_finegoldii', 'Roseburia_intestinalis', 'Clostridiaceae_bacterium', 'Phocaeicola_dorei', 'Faecalimonas_umbilicata', 'GGB3005_SGB3996', 'Bacteroides_stercoris', \n","    'Mediterraneibacter_faecis', 'Anaerostipes_hadrus', 'Enterococcus_faecalis', 'P42-PWY: incomplete reductive TCA cycle', 'PWY-5913: partial TCA cycle (obligate autotrophs)', \n","    'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', 'PWY-6143: CMP-pseudaminate biosynthesis', 'FERMENTATION-PWY: mixed acid fermentation', \n","    'DENOVOPURINE2-PWY: superpathway of purine nucleotides de novo biosynthesis II', \n","    'GLYCOLYSIS-TCA-GLYOX-BYPASS: superpathway of glycolysis, pyruvate dehydrogenase, TCA, and glyoxylate bypass', 'PWY-1269: CMP-3-deoxy-D-manno-octulosonate biosynthesis'\n","]\n","features_timepoint_24 = [\n","    'Alistipes_shahii', 'Blautia_faecis', 'Lachnospira_eligens', 'Blautia_wexlerae', 'Blautia_massiliensis', 'Roseburia_inulinivorans', 'Phocaeicola_dorei', \n","    'Parabacteroides_distasonis', 'Bacteroides_thetaiotaomicron', 'Faecalibacterium_prausnitzii', 'Romboutsia_timonensis', 'Clostridium_SGB6179', 'Ruminococcus_bicirculans', \n","    'Bifidobacterium_pseudocatenulatum', 'Bacteroides_xylanisolvens', 'Longicatena_caecimuris', 'Roseburia_sp_AF02_12', 'Veillonella_ratti', \n","    'P621-PWY: nylon-6 oligomer degradation', 'POLYAMINSYN3-PWY: superpathway of polyamine biosynthesis II', \n","    'HCAMHPDEG-PWY: 3-phenylpropanoate and 3-(3-hydroxyphenyl)propanoate degradation to 2-hydroxypentadienoate', 'GLUCOSE1PMETAB-PWY: glucose and glucose-1-phosphate degradation', \n","    'PWY-5104: L-isoleucine biosynthesis IV', 'PWY-5188: tetrapyrrole biosynthesis I (from glutamate)', 'PWY-5030: L-histidine degradation III', \n","    'GLUCUROCAT-PWY: superpathway of &beta;-D-glucuronosides degradation'\n","]\n","\n","features_timepoint_27 = [\n","    'Dorea_longicatena', 'Lachnospira_eligens', 'Bifidobacterium_bifidum', 'Parabacteroides_merdae', 'Bacteroides_uniformis', 'Blautia_wexlerae', 'Bifidobacterium_adolescentis', \n","    'Bacteroides_fragilis', 'Blautia_massiliensis', 'Faecalibacterium_prausnitzii', 'Lachnospira_pectinoschiza', 'Blautia_hansenii', 'Gemmiger_formicilis', 'Alistipes_shahii', \n","    'Anaerobutyricum_hallii', 'ORNDEG-PWY: superpathway of ornithine degradation', 'KETOGLUCONMET-PWY: ketogluconate metabolism', \n","    'P105-PWY: TCA cycle IV (2-oxoglutarate decarboxylase)', 'P125-PWY: superpathway of (R,R)-butanediol biosynthesis', 'P108-PWY: pyruvate fermentation to propanoate I', \n","    'FERMENTATION-PWY: mixed acid fermentation', 'P23-PWY: reductive TCA cycle I', 'GLYOXYLATE-BYPASS: glyoxylate cycle', 'P621-PWY: nylon-6 oligomer degradation', \n","    'COBALSYN-PWY: superpathway of adenosylcobalamin salvage from cobinamide I', 'NAGLIPASYN-PWY: lipid IVA biosynthesis (E. coli)', \n","    'P4-PWY: superpathway of L-lysine, L-threonine and L-methionine biosynthesis I', 'METH-ACETATE-PWY: methanogenesis from acetate', \n","    'HEME-BIOSYNTHESIS-II-1: heme b biosynthesis V (aerobic)', 'MET-SAM-PWY: superpathway of S-adenosyl-L-methionine biosynthesis', 'GALACTARDEG-PWY: D-galactarate degradation I', \n","    'GLUCARGALACTSUPER-PWY: superpathway of D-glucarate and D-galactarate degradation', 'PHOSLIPSYN-PWY: superpathway of phospholipid biosynthesis I (bacteria)', \n","    'METSYN-PWY: superpathway of L-homoserine and L-methionine biosynthesis', 'GLUCARDEG-PWY: D-glucarate degradation I', \n","    'GLYCOLYSIS-E-D: superpathway of glycolysis and the Entner-Doudoroff pathway', 'HOMOSER-METSYN-PWY: L-methionine biosynthesis I', \n","    'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)'\n","]\n","features_timepoint_30 = [\n","    'Anaerobutyricum_soehngenii', 'Parabacteroides_distasonis', 'Dorea_longicatena', 'Flavonifractor_plautii', 'Brotolimicola_acetigignens', 'Phocaeicola_dorei', \n","    'Lachnospira_eligens', 'GGB9480_SGB14874', 'Bacteroides_thetaiotaomicron', 'Bacteroides_caccae', 'Eubacterium_rectale', 'Blautia_hansenii', \n","    'P42-PWY: incomplete reductive TCA cycle', 'PWY-5497: purine nucleobases degradation II (anaerobic)', 'PPGPPMET-PWY: ppGpp metabolism', 'PWY-5030: L-histidine degradation III', \n","    'PWY-5505: L-glutamate and L-glutamine biosynthesis', 'ARGININE-SYN4-PWY: L-ornithine biosynthesis II', 'PWY-1269: CMP-3-deoxy-D-manno-octulosonate biosynthesis', \n","    'PWY-5981: CDP-diacylglycerol biosynthesis III', 'DAPLYSINESYN-PWY: L-lysine biosynthesis I', 'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', \n","    'P124-PWY: Bifidobacterium shunt', 'GLYCOLYSIS: glycolysis I (from glucose 6-phosphate)'\n","]\n","\n","features_timepoint_33 = [\n","    'Alistipes_putredinis', 'Bifidobacterium_adolescentis', 'GGB51647_SGB4348', 'Bacteroides_uniformis', 'Akkermansia_muciniphila', 'Lachnospira_pectinoschiza', \n","    'Faecalibacterium_sp_HTFF', 'Phocaeicola_dorei', 'P164-PWY: purine nucleobases degradation I (anaerobic)', 'PWY-5130: 2-oxobutanoate degradation I', \n","    'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)', 'GLYCOCAT-PWY: glycogen degradation I', 'POLYAMINSYN3-PWY: superpathway of polyamine biosynthesis II', \n","    'P125-PWY: superpathway of (R,R)-butanediol biosynthesis', 'PWY-6588: pyruvate fermentation to acetone', 'PWY-5971: palmitate biosynthesis (type II fatty acid synthase)', \n","    'PWY-6630: superpathway of L-tyrosine biosynthesis', 'PWY-6892: thiazole component of thiamine diphosphate biosynthesis I', 'PWY-5005: biotin biosynthesis II', \n","    'PWY-5136: fatty acid &beta;-oxidation II (plant peroxisome)', 'PRPP-PWY: superpathway of histidine, purine, and pyrimidine biosynthesis', \n","    'PWY-6478: GDP-D-glycero-&alpha;-D-manno-heptose biosynthesis', 'PWY-5981: CDP-diacylglycerol biosynthesis III'\n","]\n","\n","# Define a function to evaluate combinations of feature selectors and models\n","def evaluate_models(data, max_timepoint):\n","    results = {}\n","\n","    # Define a function to process each time point independently\n","    def process_time_point(time_point):\n","        print(f\"Processing time point: {time_point}\")\n","\n","        # Select appropriate features based on the time point\n","        if time_point == 12:\n","            selected_features = features_timepoint_12\n","        elif time_point == 15:\n","            selected_features = features_timepoint_15\n","        elif time_point == 18:\n","            selected_features = features_timepoint_18\n","        elif time_point == 21:\n","            selected_features = features_timepoint_21\n","        elif time_point == 24:\n","            selected_features = features_timepoint_24\n","        elif time_point == 27:\n","            selected_features = features_timepoint_27\n","        elif time_point == 30:\n","            selected_features = features_timepoint_30\n","        elif time_point == 33:\n","            selected_features = features_timepoint_33\n","        else:\n","            print(f\"No predefined features for time point {time_point}.\")\n","            return time_point, None\n","\n","        # Filter data for the current time point and extract selected features\n","        current_data = data[data['timepoint_numeric'] == time_point]\n","        X = current_data[selected_features]  # Feature matrix\n","        y = current_data['Diagnosis'] # Labels\n","\n","        # Ensure there are enough samples to perform LOOCV\n","        if len(y) < 2:\n","            print(f\"Skipping time point {time_point} due to insufficient samples.\")\n","            return time_point, None\n","\n","        # Initialize Leave-One-Out cross-validation\n","        loo = LeaveOneOut()\n","        best_overall_score = 0\n","        best_overall_setup = {}\n","\n","        # Define a function to process each feature selector and model combination\n","        def process_combination(feature_selector_name, ml_model_name):\n","            all_selected_features = []\n","            all_importances = []\n","\n","            # Loop through the training/test splits generated by LOOCV\n","            for train_index, test_index in loo.split(X):\n","                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                # Perform feature selection based on the specified selector\n","                if feature_selector_name == 'LASSO':\n","                    feature_selector = LassoCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30)).fit(X_train, y_train)\n","                else:\n","                    feature_selector = ElasticNetCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7).fit(X_train, y_train)\n","\n","                # Select features with non-zero coefficients\n","                selected_features = X_train.columns[feature_selector.coef_ != 0]\n","                selected_features = selected_features[:min(len(selected_features), int(0.8 * len(y_train)))]\n","\n","                # If no features are selected, skip this iteration\n","                if len(selected_features) == 0:\n","                    continue\n","\n","                # Select the relevant features from the training set\n","                X_train_selected = X_train[selected_features]\n","\n","                # Perform logistic regression for ranking the selected features based on importance\n","                logistic = LogisticRegression(max_iter=10000, random_state=42, solver='liblinear').fit(X_train_selected, y_train)\n","                importances = abs(logistic.coef_[0])\n","                ranked_features = sorted(zip(selected_features, importances), key=lambda x: x[1], reverse=True)\n","\n","                # Store selected features and their importance\n","                all_selected_features.extend([f[0] for f in ranked_features])\n","                all_importances.extend([f[1] for f in ranked_features])\n","\n","            # If no features were selected across all folds, return None\n","            if not all_selected_features:\n","                return None\n","\n","            # Aggregate selected features across all folds\n","            unique_features = list(set(all_selected_features))\n","            frequency = Counter(all_selected_features)\n","            avg_importance = {feature: np.mean([imp for feat, imp in zip(all_selected_features, all_importances) if feat == feature])\n","                              for feature in unique_features}\n","\n","            # Calculate a composite score for each feature based on frequency and importance\n","            composite_scores = {feature: 0.5 * (frequency[feature] / loo.get_n_splits(X)) + 0.5 * (avg_importance[feature] / sum(avg_importance.values()))\n","                                for feature in unique_features}\n","            sorted_features = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","            # Evaluate different feature subsets with varying thresholds\n","            best_overall_performance = 0\n","            best_overall_setup = {}\n","            best_percentage = 0\n","            thresholds = np.linspace(0.05, 0.95, 19)\n","\n","            for i in range(1, min(len(sorted_features), int(0.8 * len(y))) + 1):\n","                selected_features = [feature[0] for feature in sorted_features[:i]]\n","                best_performance_for_features = 0\n","                best_threshold_for_features = None\n","\n","                for threshold in thresholds:\n","                    fold_f1_scores = []\n","\n","                    # Perform LOOCV prediction with the selected features and model\n","                    for train_index, test_index in loo.split(X):\n","                        X_train, X_test = X.iloc[train_index][selected_features], X.iloc[test_index][selected_features]\n","                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                        # Use the appropriate model for prediction\n","                        if ml_model_name == 'ElasticNet':\n","                            model = ElasticNetCV(cv=5, max_iter=10000, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7)\n","                        elif ml_model_name == 'RandomForest':\n","                            model = RandomForestClassifier(n_estimators=300, random_state=42)\n","                        else:\n","                            model = xgb.XGBClassifier(n_estimators=500, learning_rate=0.1, eval_metric='logloss', random_state=42)\n","\n","                        # Fit the model, make predictions and compute F1 score for the current fold\n","                        model.fit(X_train, y_train)\n","                        test_prediction = (model.predict(X_test) >= threshold).astype(int) if ml_model_name == 'ElasticNet' else (model.predict_proba(X_test)[:, 1] >= threshold).astype(int)\n","                        f1_score_current = f1_score(y_test, test_prediction, average='macro')\n","                        fold_f1_scores.append(f1_score_current)\n","\n","                    # Calculate the average F1 score for the current threshold\n","                    f1_score_avg = np.mean(fold_f1_scores)\n","\n","                    # Record the best performance and threshold for the features\n","                    if f1_score_avg > best_performance_for_features:\n","                        best_performance_for_features = f1_score_avg\n","                        best_threshold_for_features = threshold\n","\n","                # Update the best overall performance if it improves\n","                if best_performance_for_features > best_overall_performance:\n","                    best_overall_performance = best_performance_for_features\n","                    best_overall_setup = {\n","                        'features': selected_features,\n","                        'threshold': best_threshold_for_features,\n","                        'performance': best_performance_for_features,\n","                        'feature_selection_method': feature_selector_name,\n","                        'ml_model': ml_model_name\n","                    }\n","\n","            return {\n","                'feature_selection_method': best_overall_setup['feature_selection_method'],\n","                'ml_model': best_overall_setup['ml_model'],\n","                'best_features': best_overall_setup['features'],\n","                'features_length': len(best_overall_setup['features']),\n","                'best_threshold': best_overall_setup['threshold'],\n","                'best_performance': best_overall_setup['performance']\n","            }\n","\n","        # Process combinations of feature selection and prediction models\n","        combinations = [('LASSO', 'ElasticNet'), ('ElasticNet', 'ElasticNet')]\n","        results_per_combination = [process_combination(fs, ml) for fs, ml in combinations]\n","        best_combination = max(results_per_combination, key=lambda x: x['best_performance'] if x is not None else 0)\n","\n","        return time_point, best_combination\n","\n","    # Process time points within the specified max_timepoint\n","    time_points = np.sort(data[data['timepoint_numeric'] < max_timepoint]['timepoint_numeric'].unique())\n","    results_parallel = Parallel(n_jobs=-1)(delayed(process_time_point)(tp) for tp in time_points)\n","    results = {tp: result for tp, result in results_parallel if result is not None}\n","\n","    return results\n","\n","# Set the max timepoint for late onset groups\n","late_onset_max_timepoint = 36\n","\n","# Evaluate models for late onset group\n","print(\"Evaluating Late Onset Group\")\n","results_late_onset = evaluate_models(late_onset_data, late_onset_max_timepoint)\n","\n","# Print results for late onset group\n","print(\"Results for Late Onset Group:\")\n","for time_point, res in results_late_onset.items():\n","    if res is not None:\n","        print(f\"Time Point: {time_point}\")\n","        print(f\"  Feature Selection Method: {res['feature_selection_method']}\")\n","        print(f\"  Machine Learning Model: {res['ml_model']}\")\n","        print(f\"  Best F1 Score: {res['best_performance']}\")\n","        print(f\"  Best Threshold: {res['best_threshold']}\")\n","        print(f\"  Features Used: {res['best_features']}\")\n","        print(f\"  Features Length: {res['features_length']}\")\n","        print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","# Define selected features for each time point\n","features_timepoint_12 = [\n","    'Veillonella_dispar', 'Lachnospira_pectinoschiza', 'Phocaeicola_dorei', 'Gemmiger_formicilis', 'Bifidobacterium_breve', 'Bifidobacterium_dentium', \n","    'Enterococcus_faecium', 'Roseburia_inulinivorans', 'Escherichia_coli', 'Parabacteroides_merdae', 'Enterococcus_avium', 'Bifidobacterium_pseudocatenulatum', \n","    'Alistipes_putredinis', 'Faecalibacterium_sp_HTFF', 'Lacticaseibacillus_rhamnosus', 'PWY-5005: biotin biosynthesis II', 'PWY-5838: superpathway of menaquinol-8 biosynthesis I'\n","]\n","\n","features_timepoint_15 = [\n","    'Veillonella_ratti', 'Longicatena_caecimuris', 'Erysipelatoclostridium_ramosum', 'Anaerobutyricum_soehngenii', 'Roseburia_intestinalis', \n","    'Bifidobacterium_pseudocatenulatum', 'Sutterella_wadsworthensis', 'Phocaeicola_dorei', 'Roseburia_faecis', 'Bacteroides_uniformis', 'Faecalibacterium_sp_HTFF', \n","    'HISDEG-PWY: L-histidine degradation I', 'P23-PWY: reductive TCA cycle I', 'ARGININE-SYN4-PWY: L-ornithine biosynthesis II', \n","    'CENTFERM-PWY: pyruvate fermentation to butanoate', 'P621-PWY: nylon-6 oligomer degradation', 'P562-PWY: myo-inositol degradation I', \n","    'P461-PWY: hexitol fermentation to lactate, formate, ethanol and acetate', 'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', \n","    'COLANSYN-PWY: colanic acid building blocks biosynthesis', 'NAGLIPASYN-PWY: lipid IVA biosynthesis (E. coli)', 'LIPA-CORESYN-PWY: lipid A-core biosynthesis (E. coli K-12)', \n","    'LPSSYN-PWY: superpathway of lipopolysaccharide biosynthesis', 'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)', \n","    'PROPFERM-PWY: superpathway of L-alanine fermentation (Stickland reaction)', 'P161-PWY: acetylene degradation (anaerobic)', 'GALACTITOLCAT-PWY: galactitol degradation', \n","    'GLCMANNANAUT-PWY: superpathway of N-acetylglucosamine, N-acetylmannosamine and N-acetylneuraminate degradation', \n","    'PWY-1861: formaldehyde assimilation II (assimilatory RuMP Cycle)', 'METHGLYUT-PWY: superpathway of methylglyoxal degradation', 'CITRULBIO-PWY: L-citrulline biosynthesis', \n","    'DENITRIFICATION-PWY: nitrate reduction I (denitrification)'\n","]\n","features_timepoint_18 = [\n","    'Streptococcus_thermophilus', 'Lactococcus_lactis', 'Bifidobacterium_adolescentis', 'GGB51647_SGB4348', 'Fusicatenibacter_saccharivorans', 'Phocaeicola_dorei', \n","    'Streptococcus_salivarius', 'Faecalibacterium_sp_HTFF', 'Alistipes_putredinis', 'Anaerobutyricum_hallii', 'Gemmiger_formicilis', 'Bifidobacterium_longum', \n","    'Blautia_caecimuris', 'GLUDEG-I-PWY: GABA shunt', 'PWY-5861: superpathway of demethylmenaquinol-8 biosynthesis I', 'P42-PWY: incomplete reductive TCA cycle', \n","    'ARG+POLYAMINE-SYN: superpathway of arginine and polyamine biosynthesis', 'DENOVOPURINE2-PWY: superpathway of purine nucleotides de novo biosynthesis II', \n","    'PWY-5022: 4-aminobutanoate degradation V', 'P621-PWY: nylon-6 oligomer degradation', 'PWY-561: superpathway of glyoxylate cycle and fatty acid degradation', \n","    'PWY-5918: superpathway of heme b biosynthesis from glutamate', 'GLYCOLYSIS-E-D: superpathway of glycolysis and the Entner-Doudoroff pathway', \n","    'PWY-5005: biotin biosynthesis II', 'PWY-5994: palmitate biosynthesis (type I fatty acid synthase)', 'PWY-241: C4 photosynthetic carbon assimilation cycle, NADP-ME type', \n","    'HEME-BIOSYNTHESIS-II: heme b biosynthesis I (aerobic)', 'CITRULBIO-PWY: L-citrulline biosynthesis', 'PWY-5686: UMP biosynthesis I', \n","    'BIOTIN-BIOSYNTHESIS-PWY: biotin biosynthesis I'\n","]\n","\n","features_timepoint_21 = [\n","    'Alistipes_finegoldii', 'Roseburia_intestinalis', 'Clostridiaceae_bacterium', 'Phocaeicola_dorei', 'Faecalimonas_umbilicata', 'GGB3005_SGB3996', 'Bacteroides_stercoris', \n","    'Mediterraneibacter_faecis', 'Anaerostipes_hadrus', 'Enterococcus_faecalis', 'P42-PWY: incomplete reductive TCA cycle', 'PWY-5913: partial TCA cycle (obligate autotrophs)', \n","    'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', 'PWY-6143: CMP-pseudaminate biosynthesis', 'FERMENTATION-PWY: mixed acid fermentation', \n","    'DENOVOPURINE2-PWY: superpathway of purine nucleotides de novo biosynthesis II', \n","    'GLYCOLYSIS-TCA-GLYOX-BYPASS: superpathway of glycolysis, pyruvate dehydrogenase, TCA, and glyoxylate bypass', 'PWY-1269: CMP-3-deoxy-D-manno-octulosonate biosynthesis'\n","]\n","features_timepoint_24 = [\n","    'Alistipes_shahii', 'Blautia_faecis', 'Lachnospira_eligens', 'Blautia_wexlerae', 'Blautia_massiliensis', 'Roseburia_inulinivorans', 'Phocaeicola_dorei', \n","    'Parabacteroides_distasonis', 'Bacteroides_thetaiotaomicron', 'Faecalibacterium_prausnitzii', 'Romboutsia_timonensis', 'Clostridium_SGB6179', 'Ruminococcus_bicirculans', \n","    'Bifidobacterium_pseudocatenulatum', 'Bacteroides_xylanisolvens', 'Longicatena_caecimuris', 'Roseburia_sp_AF02_12', 'Veillonella_ratti', \n","    'P621-PWY: nylon-6 oligomer degradation', 'POLYAMINSYN3-PWY: superpathway of polyamine biosynthesis II', \n","    'HCAMHPDEG-PWY: 3-phenylpropanoate and 3-(3-hydroxyphenyl)propanoate degradation to 2-hydroxypentadienoate', 'GLUCOSE1PMETAB-PWY: glucose and glucose-1-phosphate degradation', \n","    'PWY-5104: L-isoleucine biosynthesis IV', 'PWY-5188: tetrapyrrole biosynthesis I (from glutamate)', 'PWY-5030: L-histidine degradation III', \n","    'GLUCUROCAT-PWY: superpathway of &beta;-D-glucuronosides degradation'\n","]\n","\n","features_timepoint_27 = [\n","    'Dorea_longicatena', 'Lachnospira_eligens', 'Bifidobacterium_bifidum', 'Parabacteroides_merdae', 'Bacteroides_uniformis', 'Blautia_wexlerae', 'Bifidobacterium_adolescentis', \n","    'Bacteroides_fragilis', 'Blautia_massiliensis', 'Faecalibacterium_prausnitzii', 'Lachnospira_pectinoschiza', 'Blautia_hansenii', 'Gemmiger_formicilis', 'Alistipes_shahii', \n","    'Anaerobutyricum_hallii', 'ORNDEG-PWY: superpathway of ornithine degradation', 'KETOGLUCONMET-PWY: ketogluconate metabolism', \n","    'P105-PWY: TCA cycle IV (2-oxoglutarate decarboxylase)', 'P125-PWY: superpathway of (R,R)-butanediol biosynthesis', 'P108-PWY: pyruvate fermentation to propanoate I', \n","    'FERMENTATION-PWY: mixed acid fermentation', 'P23-PWY: reductive TCA cycle I', 'GLYOXYLATE-BYPASS: glyoxylate cycle', 'P621-PWY: nylon-6 oligomer degradation', \n","    'COBALSYN-PWY: superpathway of adenosylcobalamin salvage from cobinamide I', 'NAGLIPASYN-PWY: lipid IVA biosynthesis (E. coli)', \n","    'P4-PWY: superpathway of L-lysine, L-threonine and L-methionine biosynthesis I', 'METH-ACETATE-PWY: methanogenesis from acetate', \n","    'HEME-BIOSYNTHESIS-II-1: heme b biosynthesis V (aerobic)', 'MET-SAM-PWY: superpathway of S-adenosyl-L-methionine biosynthesis', 'GALACTARDEG-PWY: D-galactarate degradation I', \n","    'GLUCARGALACTSUPER-PWY: superpathway of D-glucarate and D-galactarate degradation', 'PHOSLIPSYN-PWY: superpathway of phospholipid biosynthesis I (bacteria)', \n","    'METSYN-PWY: superpathway of L-homoserine and L-methionine biosynthesis', 'GLUCARDEG-PWY: D-glucarate degradation I', \n","    'GLYCOLYSIS-E-D: superpathway of glycolysis and the Entner-Doudoroff pathway', 'HOMOSER-METSYN-PWY: L-methionine biosynthesis I', \n","    'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)'\n","]\n","features_timepoint_30 = [\n","    'Anaerobutyricum_soehngenii', 'Parabacteroides_distasonis', 'Dorea_longicatena', 'Flavonifractor_plautii', 'Brotolimicola_acetigignens', 'Phocaeicola_dorei', \n","    'Lachnospira_eligens', 'GGB9480_SGB14874', 'Bacteroides_thetaiotaomicron', 'Bacteroides_caccae', 'Eubacterium_rectale', 'Blautia_hansenii', \n","    'P42-PWY: incomplete reductive TCA cycle', 'PWY-5497: purine nucleobases degradation II (anaerobic)', 'PPGPPMET-PWY: ppGpp metabolism', 'PWY-5030: L-histidine degradation III', \n","    'PWY-5505: L-glutamate and L-glutamine biosynthesis', 'ARGININE-SYN4-PWY: L-ornithine biosynthesis II', 'PWY-1269: CMP-3-deoxy-D-manno-octulosonate biosynthesis', \n","    'PWY-5981: CDP-diacylglycerol biosynthesis III', 'DAPLYSINESYN-PWY: L-lysine biosynthesis I', 'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', \n","    'P124-PWY: Bifidobacterium shunt', 'GLYCOLYSIS: glycolysis I (from glucose 6-phosphate)'\n","]\n","\n","features_timepoint_33 = [\n","    'Alistipes_putredinis', 'Bifidobacterium_adolescentis', 'GGB51647_SGB4348', 'Bacteroides_uniformis', 'Akkermansia_muciniphila', 'Lachnospira_pectinoschiza', \n","    'Faecalibacterium_sp_HTFF', 'Phocaeicola_dorei', 'P164-PWY: purine nucleobases degradation I (anaerobic)', 'PWY-5130: 2-oxobutanoate degradation I', \n","    'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)', 'GLYCOCAT-PWY: glycogen degradation I', 'POLYAMINSYN3-PWY: superpathway of polyamine biosynthesis II', \n","    'P125-PWY: superpathway of (R,R)-butanediol biosynthesis', 'PWY-6588: pyruvate fermentation to acetone', 'PWY-5971: palmitate biosynthesis (type II fatty acid synthase)', \n","    'PWY-6630: superpathway of L-tyrosine biosynthesis', 'PWY-6892: thiazole component of thiamine diphosphate biosynthesis I', 'PWY-5005: biotin biosynthesis II', \n","    'PWY-5136: fatty acid &beta;-oxidation II (plant peroxisome)', 'PRPP-PWY: superpathway of histidine, purine, and pyrimidine biosynthesis', \n","    'PWY-6478: GDP-D-glycero-&alpha;-D-manno-heptose biosynthesis', 'PWY-5981: CDP-diacylglycerol biosynthesis III'\n","]\n","\n","# Define a function to evaluate combinations of feature selectors and models\n","def evaluate_models(data, max_timepoint):\n","    results = {}\n","\n","    # Define a function to process each time point independently\n","    def process_time_point(time_point):\n","        print(f\"Processing time point: {time_point}\")\n","\n","        # Select appropriate features based on the time point\n","        if time_point == 12:\n","            selected_features = features_timepoint_12\n","        elif time_point == 15:\n","            selected_features = features_timepoint_15\n","        elif time_point == 18:\n","            selected_features = features_timepoint_18\n","        elif time_point == 21:\n","            selected_features = features_timepoint_21\n","        elif time_point == 24:\n","            selected_features = features_timepoint_24\n","        elif time_point == 27:\n","            selected_features = features_timepoint_27\n","        elif time_point == 30:\n","            selected_features = features_timepoint_30\n","        elif time_point == 33:\n","            selected_features = features_timepoint_33\n","        else:\n","            print(f\"No predefined features for time point {time_point}.\")\n","            return time_point, None\n","\n","        # Filter data for the current time point and extract selected features\n","        current_data = data[data['timepoint_numeric'] == time_point]\n","        X = current_data[selected_features]  # Feature matrix\n","        y = current_data['Diagnosis'] # Labels\n","\n","        # Ensure there are enough samples to perform LOOCV\n","        if len(y) < 2:\n","            print(f\"Skipping time point {time_point} due to insufficient samples.\")\n","            return time_point, None\n","\n","        # Initialize Leave-One-Out cross-validation\n","        loo = LeaveOneOut()\n","        best_overall_score = 0\n","        best_overall_setup = {}\n","\n","        # Define a function to process each feature selector and model combination\n","        def process_combination(feature_selector_name, ml_model_name):\n","            all_selected_features = []\n","            all_importances = []\n","\n","            # Loop through the training/test splits generated by LOOCV\n","            for train_index, test_index in loo.split(X):\n","                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                # Perform feature selection based on the specified selector\n","                if feature_selector_name == 'LASSO':\n","                    feature_selector = LassoCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30)).fit(X_train, y_train)\n","                else:\n","                    feature_selector = ElasticNetCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7).fit(X_train, y_train)\n","\n","                # Select features with non-zero coefficients\n","                selected_features = X_train.columns[feature_selector.coef_ != 0]\n","                selected_features = selected_features[:min(len(selected_features), int(0.8 * len(y_train)))]\n","\n","                # If no features are selected, skip this iteration\n","                if len(selected_features) == 0:\n","                    continue\n","\n","                # Select the relevant features from the training set\n","                X_train_selected = X_train[selected_features]\n","\n","                # Perform logistic regression for ranking the selected features based on importance\n","                logistic = LogisticRegression(max_iter=10000, random_state=42, solver='liblinear').fit(X_train_selected, y_train)\n","                importances = abs(logistic.coef_[0])\n","                ranked_features = sorted(zip(selected_features, importances), key=lambda x: x[1], reverse=True)\n","\n","                # Store selected features and their importance\n","                all_selected_features.extend([f[0] for f in ranked_features])\n","                all_importances.extend([f[1] for f in ranked_features])\n","\n","            # If no features were selected across all folds, return None\n","            if not all_selected_features:\n","                return None\n","\n","            # Aggregate selected features across all folds\n","            unique_features = list(set(all_selected_features))\n","            frequency = Counter(all_selected_features)\n","            avg_importance = {feature: np.mean([imp for feat, imp in zip(all_selected_features, all_importances) if feat == feature])\n","                              for feature in unique_features}\n","\n","            # Calculate a composite score for each feature based on frequency and importance\n","            composite_scores = {feature: 0.5 * (frequency[feature] / loo.get_n_splits(X)) + 0.5 * (avg_importance[feature] / sum(avg_importance.values()))\n","                                for feature in unique_features}\n","            sorted_features = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","            # Evaluate different feature subsets with varying thresholds\n","            best_overall_performance = 0\n","            best_overall_setup = {}\n","            best_percentage = 0\n","            thresholds = np.linspace(0.05, 0.95, 19)\n","\n","            for i in range(1, min(len(sorted_features), int(0.8 * len(y))) + 1):\n","                selected_features = [feature[0] for feature in sorted_features[:i]]\n","                best_performance_for_features = 0\n","                best_threshold_for_features = None\n","\n","                for threshold in thresholds:\n","                    fold_f1_scores = []\n","\n","                    # Perform LOOCV prediction with the selected features and model\n","                    for train_index, test_index in loo.split(X):\n","                        X_train, X_test = X.iloc[train_index][selected_features], X.iloc[test_index][selected_features]\n","                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                        # Use the appropriate model for prediction\n","                        if ml_model_name == 'ElasticNet':\n","                            model = ElasticNetCV(cv=5, max_iter=10000, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7)\n","                        elif ml_model_name == 'RandomForest':\n","                            model = RandomForestClassifier(n_estimators=300, random_state=42)\n","                        else:\n","                            model = xgb.XGBClassifier(n_estimators=500, learning_rate=0.1, eval_metric='logloss', random_state=42)\n","\n","                        # Fit the model, make predictions and compute F1 score for the current fold\n","                        model.fit(X_train, y_train)\n","                        test_prediction = (model.predict(X_test) >= threshold).astype(int) if ml_model_name == 'ElasticNet' else (model.predict_proba(X_test)[:, 1] >= threshold).astype(int)\n","                        f1_score_current = f1_score(y_test, test_prediction, average='macro')\n","                        fold_f1_scores.append(f1_score_current)\n","\n","                    # Calculate the average F1 score for the current threshold\n","                    f1_score_avg = np.mean(fold_f1_scores)\n","\n","                    # Record the best performance and threshold for the features\n","                    if f1_score_avg > best_performance_for_features:\n","                        best_performance_for_features = f1_score_avg\n","                        best_threshold_for_features = threshold\n","\n","                # Update the best overall performance if it improves\n","                if best_performance_for_features > best_overall_performance:\n","                    best_overall_performance = best_performance_for_features\n","                    best_overall_setup = {\n","                        'features': selected_features,\n","                        'threshold': best_threshold_for_features,\n","                        'performance': best_performance_for_features,\n","                        'feature_selection_method': feature_selector_name,\n","                        'ml_model': ml_model_name\n","                    }\n","\n","            return {\n","                'feature_selection_method': best_overall_setup['feature_selection_method'],\n","                'ml_model': best_overall_setup['ml_model'],\n","                'best_features': best_overall_setup['features'],\n","                'features_length': len(best_overall_setup['features']),\n","                'best_threshold': best_overall_setup['threshold'],\n","                'best_performance': best_overall_setup['performance']\n","            }\n","\n","        # Process combinations of feature selection and prediction models\n","        combinations = [('LASSO', 'ElasticNet'), ('ElasticNet', 'ElasticNet'), \n","                        ('LASSO', 'RandomForest'), ('ElasticNet', 'RandomForest'), \n","                        ('LASSO', 'XGBoost'), ('ElasticNet', 'XGBoost')]\n","        results_per_combination = [process_combination(fs, ml) for fs, ml in combinations]\n","        best_combination = max(results_per_combination, key=lambda x: x['best_performance'] if x is not None else 0)\n","\n","        return time_point, best_combination\n","\n","    # Process time points within the specified max_timepoint\n","    time_points = np.sort(data[data['timepoint_numeric'] < max_timepoint]['timepoint_numeric'].unique())\n","    results_parallel = Parallel(n_jobs=-1)(delayed(process_time_point)(tp) for tp in time_points)\n","    results = {tp: result for tp, result in results_parallel if result is not None}\n","\n","    return results\n","\n","# Set the max timepoint for late onset groups\n","late_onset_max_timepoint = 36\n","\n","# Evaluate models for late onset group\n","print(\"Evaluating Late Onset Group\")\n","results_late_onset = evaluate_models(late_onset_data, late_onset_max_timepoint)\n","\n","# Print results for late onset group\n","print(\"Results for Late Onset Group:\")\n","for time_point, res in results_late_onset.items():\n","    if res is not None:\n","        print(f\"Time Point: {time_point}\")\n","        print(f\"  Feature Selection Method: {res['feature_selection_method']}\")\n","        print(f\"  Machine Learning Model: {res['ml_model']}\")\n","        print(f\"  Best F1 Score: {res['best_performance']}\")\n","        print(f\"  Best Threshold: {res['best_threshold']}\")\n","        print(f\"  Features Used: {res['best_features']}\")\n","        print(f\"  Features Length: {res['features_length']}\")\n","        print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"elapsed":835,"status":"ok","timestamp":1716337861382,"user":{"displayName":"ZHIQI ZHANG","userId":"11425140851942185431"},"user_tz":240},"id":"Lm_onMZwtMO6","outputId":"65d0c69a-ce52-4932-b2f8-ad6e5058330b"},"outputs":[],"source":["# Create a line chart to show the F1 score for each time point\n","# Sorting the time points\n","sorted_features_time_points = [12, 15]\n","sorted_features_f1_scores = [90, 87]\n","\n","# Create the line chart\n","plt.figure(figsize=(8, 4))\n","\n","# Plot the line with points and set line color, marker size, and style\n","plt.plot(sorted_features_time_points, sorted_features_f1_scores, marker='o', linestyle='-', color='blue', markersize=10)\n","\n","# Add labels to each point\n","for i, score in enumerate(sorted_features_f1_scores):\n","    plt.text(sorted_features_time_points[i], score + 1, f\"{score}\", ha='center', va='bottom', fontsize=14)\n","\n","# Add titles and labels\n","plt.title('F1 Score by Age for Early Onset Combined Species and Pathways Abundance Data', fontsize=14, color='blue', pad=20)\n","plt.xlabel('Age (Months)', fontsize=14)\n","plt.ylabel('Average F1 Score', fontsize=14)\n","\n","# Adjust the axis limits\n","plt.xticks(sorted_features_time_points, fontsize=12)\n","plt.ylim(0, 100)\n","plt.yticks(fontsize=12)\n","\n","# Show the plot with tight layout\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a line chart to show the F1 score for each time point\n","# Sorting the time points\n","sorted_features_time_points = [12, 15, 18, 21, 24, 27, 30, 33]\n","sorted_features_f1_scores = [97, 91, 94, 90, 94, 85, 85, 93]\n","\n","# Create the line chart\n","plt.figure(figsize=(8, 4))\n","\n","# Plot the line with points and set line color, marker size, and style\n","plt.plot(sorted_features_time_points, sorted_features_f1_scores, marker='o', linestyle='-', color='blue', markersize=10)\n","\n","# Add labels to each point\n","for i, score in enumerate(sorted_features_f1_scores):\n","    plt.text(sorted_features_time_points[i], score + 1, f\"{score}\", ha='center', va='bottom', fontsize=14)\n","\n","# Add titles and labels\n","plt.title('F1 Score by Age for Late Onset Combined Species and Pathways Abundance Data', fontsize=14, color='blue', pad=20)\n","plt.xlabel('Age (Months)', fontsize=14)\n","plt.ylabel('Average F1 Score', fontsize=14)\n","\n","# Adjust the axis limits\n","plt.xticks(sorted_features_time_points, fontsize=12)\n","plt.ylim(0, 100)\n","plt.yticks(fontsize=12)\n","\n","# Show the plot with tight layout\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
