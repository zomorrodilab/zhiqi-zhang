{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YH20TaYMfOPx"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import sys\n","import os\n","if not sys.warnoptions:\n","    warnings.simplefilter(\"ignore\")\n","    os.environ[\"PYTHONWARNINGS\"] = \"ignore::UserWarning\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5mHH-frLYN_I"},"outputs":[],"source":["# Load packages\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import re\n","from collections import Counter, defaultdict\n","from joblib import Parallel, delayed\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import SelectKBest, f_classif, RFE\n","from sklearn.linear_model import LassoCV, LogisticRegression, LogisticRegressionCV, ElasticNetCV, ElasticNet\n","from sklearn.metrics import f1_score, roc_auc_score\n","from sklearn.model_selection import LeaveOneOut, KFold, GridSearchCV, StratifiedKFold\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","import statistics\n","import xgboost as xgb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"executionInfo":{"elapsed":5126,"status":"ok","timestamp":1716746521218,"user":{"displayName":"ZHIQI ZHANG","userId":"11425140851942185431"},"user_tz":240},"id":"zO7a90AvYqwL","outputId":"03b794b3-887f-4421-eda9-22048738a493"},"outputs":[],"source":["# Load dataset\n","species_data = pd.read_excel('species_abundance_merged_2024-08-13.xlsx')\n","pathway_data = pd.read_excel('pathway_abundance_merged_2024-08-21.xlsx')\n","\n","# List of columns to merge on\n","merge_columns = ['SampleID', 'Subject', 'Subject_number', 'timepoint_numeric', 'Diagnosis', 'CD_onset', 'Relative_timepoint', 'Country']\n","\n","# Perform the merge\n","combined_data = pd.merge(species_data, pathway_data, on=merge_columns, how='inner')\n","combined_data"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Exclude subjects with a CD onset of 12 months\n","excluded_subjects = [23, 31]\n","combined_data = combined_data[~combined_data['Subject_number'].isin(excluded_subjects)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to apply abundance and prevalence thresholds\n","def filter_features(data, abundance_threshold = 0.001, prevalence_threshold = 0.1):\n","    initial_features_count = data.shape[1] - 8\n","    sample_count = data.shape[0]\n","    \n","    # Calculate prevalence threshold\n","    min_prevalent_samples = int(prevalence_threshold * sample_count)\n","\n","    # Filter features based on the thresholds\n","    features_columns = data.columns.difference(['SampleID', 'Subject', 'Subject_number', 'timepoint_numeric', 'Diagnosis', 'CD_onset', 'Relative_timepoint', 'Country'])\n","    features_data = data[features_columns]\n","    \n","    # Calculate the abundance and prevalence for each feature\n","    features_above_threshold = (features_data >= abundance_threshold).sum(axis=0) >= min_prevalent_samples\n","    filtered_features = features_columns[features_above_threshold]\n","    \n","    # Filter the data to keep only the selected species\n","    filtered_data = data[['SampleID', 'Subject', 'Subject_number', 'timepoint_numeric', 'Diagnosis', 'CD_onset', 'Relative_timepoint', 'Country'] + filtered_features.tolist()]\n","\n","    final_features_count = len(filtered_features)\n","    print(f\"Initial number of features: {initial_features_count}\")\n","    print(f\"Number of features after filtering: {final_features_count}\")\n","    \n","    return filtered_data\n","\n","# Filter the data\n","combined_data_filtered = filter_features(combined_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","# Define selected features for each time point\n","features_timepoint_12 = [\n","    'Coprococcus_comes', 'Bifidobacterium_dentium', 'Enterocloster_clostridioformis', 'Veillonella_ratti', 'Hungatella_hathewayi', \n","    'Faecalimonas_umbilicata', 'Escherichia_coli', 'GGB9469_SGB14862', 'Tyzzerella_nexilis', 'Streptococcus_thermophilus', \n","    'Alistipes_onderdonkii', 'Eggerthella_lenta', 'Roseburia_faecis', 'Bifidobacterium_pseudocatenulatum', \n","    'Bacteroides_stercoris', 'Alistipes_putredinis', 'GGB51647_SGB4348', 'Lachnospira_pectinoschiza', 'Ruminococcus_lactaris', \n","    'Faecalibacterium_sp_HTFF', 'Bifidobacterium_breve', 'Faecalibacterium_prausnitzii', 'Megasphaera_micronuciformis', \n","    'GGB9480_SGB14874', 'Enterococcus_faecalis', \n","    'PWY-5464: superpathway of cytosolic glycolysis (plants), pyruvate dehydrogenase and TCA cycle', \n","    'PWY-6143: CMP-pseudaminate biosynthesis', 'PWY-5861: superpathway of demethylmenaquinol-8 biosynthesis I', \n","    'PWY-5838: superpathway of menaquinol-8 biosynthesis I', 'PWY-5723: Rubisco shunt', \n","    'POLYAMINSYN3-PWY: superpathway of polyamine biosynthesis II', 'PWY-5920: superpathway of heme b biosynthesis from glycine', \n","    'GLYOXYLATE-BYPASS: glyoxylate cycle', 'P23-PWY: reductive TCA cycle I', \n","    'PWY-5189: tetrapyrrole biosynthesis II (from glycine)', 'P105-PWY: TCA cycle IV (2-oxoglutarate decarboxylase)', \n","    'GALACTITOLCAT-PWY: galactitol degradation', 'GLUCARDEG-PWY: D-glucarate degradation I', \n","    'METHGLYUT-PWY: superpathway of methylglyoxal degradation', \n","    'PWY-561: superpathway of glyoxylate cycle and fatty acid degradation', \n","    'PWY-5860: superpathway of demethylmenaquinol-6 biosynthesis I', \n","    'ASPASN-PWY: superpathway of L-aspartate and L-asparagine biosynthesis', 'PWY-5656: mannosylglycerate biosynthesis I', \n","    'PWY-5840: superpathway of menaquinol-7 biosynthesis', 'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)', \n","    'BIOTIN-BIOSYNTHESIS-PWY: biotin biosynthesis I', 'PWY-5345: superpathway of L-methionine biosynthesis (by sulfhydrylation)', \n","    'PWY-5705: allantoin degradation to glyoxylate III', 'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', \n","    'PWY-5136: fatty acid &beta;-oxidation II (plant peroxisome)', 'NAGLIPASYN-PWY: lipid IVA biosynthesis (E. coli)', \n","    'PWY-5896: superpathway of menaquinol-10 biosynthesis', 'PWY-5850: superpathway of menaquinol-6 biosynthesis', \n","    'PWY-5686: UMP biosynthesis I', 'GLUCARGALACTSUPER-PWY: superpathway of D-glucarate and D-galactarate degradation', \n","    'GALACTARDEG-PWY: D-galactarate degradation I', 'PWY-5897: superpathway of menaquinol-11 biosynthesis', \n","    'PWY-5898: superpathway of menaquinol-12 biosynthesis', 'PWY-5899: superpathway of menaquinol-13 biosynthesis', \n","    'GLYCOCAT-PWY: glycogen degradation I', 'PWY-5981: CDP-diacylglycerol biosynthesis III', \n","    'PWY-5505: L-glutamate and L-glutamine biosynthesis', 'P124-PWY: Bifidobacterium shunt', \n","    'ARGDEG-PWY: superpathway of L-arginine, putrescine, and 4-aminobutanoate degradation', \n","    'PWY-5004: superpathway of L-citrulline metabolism', 'PWY-5862: superpathway of demethylmenaquinol-9 biosynthesis', \n","    'PWY-5910: superpathway of geranylgeranyldiphosphate biosynthesis I (via mevalonate)', 'P221-PWY: octane oxidation', \n","    'PWY-6292: superpathway of L-cysteine biosynthesis (mammalian)', 'PWY-5675: nitrate reduction V (assimilatory)', \n","    'PWY-5845: superpathway of menaquinol-9 biosynthesis', \n","    'HCAMHPDEG-PWY: 3-phenylpropanoate and 3-(3-hydroxyphenyl)propanoate degradation to 2-hydroxypentadienoate'\n","]\n","\n","features_timepoint_15 = [\n","    'Veillonella_ratti', 'Clostridium_sp_AT4', 'Bifidobacterium_pseudocatenulatum', 'Lacticaseibacillus_rhamnosus', 'Faecalibacterium_sp_HTFF', \n","    'Phocaeicola_dorei', 'Enterococcus_faecalis', 'Ruminococcus_bromii', 'Dorea_longicatena', 'Lachnospira_pectinoschiza', 'Lacrimispora_amygdalina', \n","    'Eggerthella_lenta', 'Clostridium_SGB6179', 'Ruminococcus_gnavus', 'Sellimonas_intestinalis', 'Akkermansia_muciniphila', 'GGB9480_SGB14874', \n","    'Escherichia_coli', 'PWY-6143: CMP-pseudaminate biosynthesis', 'PWY-5920: superpathway of heme b biosynthesis from glycine', \n","    'PWY-5514: UDP-N-acetyl-D-galactosamine biosynthesis II', 'GLUCARDEG-PWY: D-glucarate degradation I', \n","    'PWY-5910: superpathway of geranylgeranyldiphosphate biosynthesis I (via mevalonate)', \n","    'FAO-PWY: fatty acid &beta;-oxidation I (generic)', 'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)', \n","    'PWY-5675: nitrate reduction V (assimilatory)', 'PWY-5850: superpathway of menaquinol-6 biosynthesis', \n","    'PWY-5896: superpathway of menaquinol-10 biosynthesis', \n","    'HCAMHPDEG-PWY: 3-phenylpropanoate and 3-(3-hydroxyphenyl)propanoate degradation to 2-hydroxypentadienoate', \n","    'METHGLYUT-PWY: superpathway of methylglyoxal degradation', 'HEME-BIOSYNTHESIS-II: heme b biosynthesis I (aerobic)', \n","    'FUC-RHAMCAT-PWY: superpathway of fucose and rhamnose degradation', 'KETOGLUCONMET-PWY: ketogluconate metabolism', \n","    'P621-PWY: nylon-6 oligomer degradation', 'FUCCAT-PWY: fucose degradation', \n","    'GLYCOLYSIS-E-D: superpathway of glycolysis and the Entner-Doudoroff pathway', 'HISDEG-PWY: L-histidine degradation I', \n","    'PWY-5367: petroselinate biosynthesis', 'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', \n","    'PWY-5189: tetrapyrrole biosynthesis II (from glycine)', 'PWY-1861: formaldehyde assimilation II (assimilatory RuMP Cycle)'\n","]\n","\n","# Define a function to evaluate combinations of feature selectors and models\n","def evaluate_models(data, max_timepoint):\n","    results = {}\n","\n","    # Define a function to process each time point independently\n","    def process_time_point(time_point):\n","        print(f\"Processing time point: {time_point}\")\n","\n","        # Select features based on the time point\n","        if time_point == 12:\n","            selected_features = features_timepoint_12\n","        elif time_point == 15:\n","            selected_features = features_timepoint_15\n","        else:\n","            print(f\"No predefined features for time point {time_point}.\")\n","            return time_point, None\n","\n","        # Filter data for the current time point and extract selected features\n","        current_data = data[data['timepoint_numeric'] == time_point]\n","        X = current_data[selected_features] # Feature matrix\n","        y = current_data['Diagnosis'] # Labels\n","\n","        # Ensure there are enough samples to perform LOOCV\n","        if len(y) < 2:\n","            print(f\"Skipping time point {time_point} due to insufficient samples.\")\n","            return time_point, None\n","\n","        # Initialize Leave-One-Out cross-validation\n","        loo = LeaveOneOut()\n","        best_overall_score = 0\n","        best_overall_setup = {}\n","\n","        # Define a function to process each feature selector and model combination\n","        def process_combination(feature_selector_name, ml_model_name):\n","            all_selected_features = []\n","            all_importances = []\n","\n","            # Loop through the training/test splits generated by LOOCV\n","            for train_index, test_index in loo.split(X):\n","                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                # Perform feature selection based on the specified selector\n","                if feature_selector_name == 'LASSO':\n","                    feature_selector = LassoCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30)).fit(X_train, y_train)\n","                else:\n","                    feature_selector = ElasticNetCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7).fit(X_train, y_train)\n","\n","                # Select features with non-zero coefficients\n","                selected_features = X_train.columns[feature_selector.coef_ != 0]\n","                selected_features = selected_features[:min(len(selected_features), int(0.8 * len(y_train)))]\n","\n","                # If no features are selected, skip this iteration\n","                if len(selected_features) == 0:\n","                    continue\n","\n","                # Select the relevant features from the training set\n","                X_train_selected = X_train[selected_features]\n","\n","                # Perform logistic regression for ranking the selected features based on importance\n","                logistic = LogisticRegression(max_iter=10000, random_state=42, solver='liblinear').fit(X_train_selected, y_train)\n","                importances = abs(logistic.coef_[0])\n","                ranked_features = sorted(zip(selected_features, importances), key=lambda x: x[1], reverse=True)\n","\n","                # Store selected features and their importance\n","                all_selected_features.extend([f[0] for f in ranked_features])\n","                all_importances.extend([f[1] for f in ranked_features])\n","\n","            # If no features were selected across all folds, return None\n","            if not all_selected_features:\n","                return None\n","\n","            # Aggregate selected features across all folds\n","            unique_features = list(set(all_selected_features))\n","            frequency = Counter(all_selected_features)\n","            avg_importance = {feature: np.mean([imp for feat, imp in zip(all_selected_features, all_importances) if feat == feature])\n","                              for feature in unique_features}\n","\n","            # Calculate a composite score for each feature based on frequency and importance\n","            composite_scores = {feature: 0.5 * (frequency[feature] / loo.get_n_splits(X)) + 0.5 * (avg_importance[feature] / sum(avg_importance.values()))\n","                                for feature in unique_features}\n","            sorted_features = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","            # Evaluate different feature subsets with varying thresholds\n","            best_overall_performance = 0\n","            best_overall_setup = {}\n","            best_percentage = 0\n","            thresholds = np.linspace(0.05, 0.95, 19)\n","\n","            for i in range(1, min(len(sorted_features), int(0.8 * len(y))) + 1):\n","                selected_features = [feature[0] for feature in sorted_features[:i]]\n","                best_performance_for_features = 0\n","                best_threshold_for_features = None\n","\n","                for threshold in thresholds:\n","                    fold_f1_scores = []\n","\n","                    # Perform LOOCV prediction with the selected features and model\n","                    for train_index, test_index in loo.split(X):\n","                        X_train, X_test = X.iloc[train_index][selected_features], X.iloc[test_index][selected_features]\n","                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                        # Use the appropriate model for prediction\n","                        if ml_model_name == 'XGBoost':\n","                            model = xgb.XGBClassifier(n_estimators=300, use_label_encoder=False, eval_metric='logloss', random_state=42)\n","                        elif ml_model_name == 'RandomForest':\n","                            model = RandomForestClassifier(n_estimators=300, random_state=42)\n","                        else:\n","                            model = ElasticNetCV(cv=5, max_iter=10000, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7)\n","\n","                        # Fit the model, make predictions and compute F1 score for the current fold\n","                        model.fit(X_train, y_train)\n","                        test_prediction = (model.predict(X_test) >= threshold).astype(int) if ml_model_name == 'ElasticNet' else (model.predict_proba(X_test)[:, 1] >= threshold).astype(int)\n","                        f1_score_current = f1_score(y_test, test_prediction, average='macro')\n","                        fold_f1_scores.append(f1_score_current)\n","\n","                    # Calculate the average F1 score for the current threshold\n","                    f1_score_avg = np.mean(fold_f1_scores)\n","\n","                    # Record the best performance and threshold for the features\n","                    if f1_score_avg > best_performance_for_features:\n","                        best_performance_for_features = f1_score_avg\n","                        best_threshold_for_features = threshold\n","\n","                # Update the best overall performance if it improves\n","                if best_performance_for_features > best_overall_performance:\n","                    best_overall_performance = best_performance_for_features\n","                    best_overall_setup = {\n","                        'features': selected_features,\n","                        'threshold': best_threshold_for_features,\n","                        'performance': best_performance_for_features,\n","                        'feature_selection_method': feature_selector_name,\n","                        'ml_model': ml_model_name\n","                    }\n","\n","            return {\n","                'feature_selection_method': best_overall_setup['feature_selection_method'],\n","                'ml_model': best_overall_setup['ml_model'],\n","                'best_features': best_overall_setup['features'],\n","                'features_length': len(best_overall_setup['features']),\n","                'best_threshold': best_overall_setup['threshold'],\n","                'best_performance': best_overall_setup['performance']\n","            }\n","\n","        # Process combinations of feature selection and prediction models\n","        combinations = [('LASSO', 'ElasticNet'), ('ElasticNet', 'ElasticNet'), ('LASSO', 'XGBoost'), ('ElasticNet', 'XGBoost')]\n","        results_per_combination = [process_combination(fs, ml) for fs, ml in combinations]\n","        best_combination = max(results_per_combination, key=lambda x: x['best_performance'] if x is not None else 0)\n","\n","        return time_point, best_combination\n","\n","    # Process time points within the specified max_timepoint\n","    time_points = np.sort(data[data['timepoint_numeric'] < max_timepoint]['timepoint_numeric'].unique())\n","    results_parallel = Parallel(n_jobs=-1)(delayed(process_time_point)(tp) for tp in time_points)\n","    results = {tp: result for tp, result in results_parallel if result is not None}\n","\n","    return results\n","\n","# Set the max timepoint to consider data before the earliest onset age\n","max_timepoint = 18\n","\n","# Evaluate models for all subjects\n","print(\"Evaluating Celiac Disease Prediction\")\n","results_ced = evaluate_models(combined_data_filtered, max_timepoint)\n","\n","# Print results for all subjects\n","print(\"Results for Celiac Disease Prediction for All Subjects:\")\n","for time_point, res in results_ced.items():\n","    if res is not None:\n","        print(f\"Time Point: {time_point}\")\n","        print(f\"  Feature Selection Method: {res['feature_selection_method']}\")\n","        print(f\"  Machine Learning Model: {res['ml_model']}\")\n","        print(f\"  Best F1 Score: {res['best_performance']}\")\n","        print(f\"  Best Threshold: {res['best_threshold']}\")\n","        print(f\"  Features Used: {res['best_features']}\")\n","        print(f\"  Features Length: {res['features_length']}\")\n","        print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","# Filter data for Celiac disease cases before 18 and 36 months\n","celiac_data = combined_data_filtered[(combined_data_filtered['Diagnosis'] == 1) & \n","                                     (combined_data_filtered['timepoint_numeric'] <= 15)]\n","\n","# Define early onset vs. late onset based on the thresholds (18 months and 36 months)\n","celiac_data['Onset_Type'] = np.where(celiac_data['CD_onset'] <= 18, 'Early', 'Late')\n","celiac_data['Onset_Type'] = np.where(celiac_data['CD_onset'] <= 36, celiac_data['Onset_Type'], 'None')\n","\n","# Remove rows where Onset_Type is 'None' (for onset after 36 months)\n","celiac_data = celiac_data[celiac_data['Onset_Type'] != 'None']\n","\n","# Encode 'Onset_Type' to numerical values: Early = 0, Late = 1\n","celiac_data['Onset_Type'] = celiac_data['Onset_Type'].map({'Early': 0, 'Late': 1})\n","\n","# Define selected features for each time point\n","features_timepoint_12 = [\n","    'Bacteroides_thetaiotaomicron', 'Bifidobacterium_breve', 'GGB3612_SGB4882', \n","    'Bifidobacterium_bifidum', 'Bifidobacterium_adolescentis', 'Bacteroides_caccae', \n","    'Eisenbergiella_tayi', 'Phocaeicola_massiliensis', 'Faecalibacterium_prausnitzii', \n","    'Ruminococcus_gnavus', 'Veillonella_parvula', 'ARO-PWY: chorismate biosynthesis I', \n","    'ARGSYN-PWY: L-arginine biosynthesis I (via L-ornithine)'\n","]\n","\n","features_timepoint_15 = [\n","    'Erysipelatoclostridium_ramosum', 'Bacteroides_fragilis', 'Blautia_producta', \n","    'Akkermansia_muciniphila', 'Enterococcus_faecalis', 'Bacteroides_stercoris', \n","    'Alistipes_onderdonkii', 'Parabacteroides_distasonis', 'Blautia_wexlerae', \n","    'Escherichia_coli', 'Alistipes_finegoldii', 'Bacteroides_thetaiotaomicron', \n","    '3-HYDROXYPHENYLACETATE-DEGRADATION-PWY: 4-hydroxyphenylacetate degradation', \n","    'ARGININE-SYN4-PWY: L-ornithine biosynthesis II', 'ANAEROFRUCAT-PWY: homolactic fermentation', \n","    '1CMET2-PWY: folate transformations III (E. coli)', 'ARGSYN-PWY: L-arginine biosynthesis I (via L-ornithine)', \n","    'ARGSYNBSUB-PWY: L-arginine biosynthesis II (acetyl cycle)', 'ARO-PWY: chorismate biosynthesis I', \n","    'ARG+POLYAMINE-SYN: superpathway of arginine and polyamine biosynthesis', 'ANAGLYCOLYSIS-PWY: glycolysis III (from glucose)', \n","    'AEROBACTINSYN-PWY: aerobactin biosynthesis', 'ARGDEG-PWY: superpathway of L-arginine, putrescine, and 4-aminobutanoate degradation', \n","    'ALLANTOINDEG-PWY: superpathway of allantoin degradation in yeast', 'BRANCHED-CHAIN-AA-SYN-PWY: superpathway of branched chain amino acid biosynthesis'\n","    \n","]\n","\n","# Define a function to evaluate combinations of feature selectors and models\n","def evaluate_models(data):\n","    results = {}\n","\n","    # Define a function to process each time point independently\n","    def process_time_point(time_point):\n","        print(f\"Processing time point: {time_point}\")\n","\n","        # Select features based on the time point\n","        if time_point == 12:\n","            selected_features = features_timepoint_12\n","        elif time_point == 15:\n","            selected_features = features_timepoint_15\n","        else:\n","            print(f\"No predefined features for time point {time_point}.\")\n","            return time_point, None\n","\n","        # Filter data for the current time point and extract selected features\n","        current_data = data[data['timepoint_numeric'] == time_point]\n","        X = current_data[selected_features] # Feature matrix\n","        y = current_data['Onset_Type'] # Labels\n","\n","        # Ensure there are enough samples to perform LOOCV\n","        if len(y) < 2:\n","            print(f\"Skipping time point {time_point} due to insufficient samples.\")\n","            return time_point, None\n","\n","        # Initialize Leave-One-Out cross-validation\n","        loo = LeaveOneOut()\n","        best_overall_score = 0\n","        best_overall_setup = {}\n","\n","        # Define a function to process each feature selector and model combination\n","        def process_combination(feature_selector_name, ml_model_name):\n","            all_selected_features = []\n","            all_importances = []\n","\n","            # Loop through the training/test splits generated by LOOCV\n","            for train_index, test_index in loo.split(X):\n","                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                # Perform feature selection based on the specified selector\n","                if feature_selector_name == 'LASSO':\n","                    feature_selector = LassoCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30)).fit(X_train, y_train)\n","                else:\n","                    feature_selector = ElasticNetCV(cv=5, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7).fit(X_train, y_train)\n","\n","                # Select features with non-zero coefficients\n","                selected_features = X_train.columns[feature_selector.coef_ != 0]\n","                selected_features = selected_features[:min(len(selected_features), int(0.8 * len(y_train)))]\n","\n","                # If no features are selected, skip this iteration\n","                if len(selected_features) == 0:\n","                    continue\n","\n","                # Select the relevant features from the training set\n","                X_train_selected = X_train[selected_features]\n","\n","                # Perform logistic regression for ranking the selected features based on importance\n","                logistic = LogisticRegression(max_iter=10000, random_state=42, solver='liblinear').fit(X_train_selected, y_train)\n","                importances = abs(logistic.coef_[0])\n","                ranked_features = sorted(zip(selected_features, importances), key=lambda x: x[1], reverse=True)\n","\n","                # Store selected features and their importance\n","                all_selected_features.extend([f[0] for f in ranked_features])\n","                all_importances.extend([f[1] for f in ranked_features])\n","\n","            # If no features were selected across all folds, return None\n","            if not all_selected_features:\n","                return None\n","\n","            # Aggregate selected features across all folds\n","            unique_features = list(set(all_selected_features))\n","            frequency = Counter(all_selected_features)\n","            avg_importance = {feature: np.mean([imp for feat, imp in zip(all_selected_features, all_importances) if feat == feature])\n","                              for feature in unique_features}\n","\n","            # Calculate a composite score for each feature based on frequency and importance\n","            composite_scores = {feature: 0.5 * (frequency[feature] / loo.get_n_splits(X)) + 0.5 * (avg_importance[feature] / sum(avg_importance.values()))\n","                                for feature in unique_features}\n","            sorted_features = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","            # Evaluate different feature subsets with varying thresholds\n","            best_overall_performance = 0\n","            best_overall_setup = {}\n","            best_percentage = 0\n","            thresholds = np.linspace(0.05, 0.95, 19)\n","\n","            for i in range(1, min(len(sorted_features), int(0.8 * len(y))) + 1):\n","                selected_features = [feature[0] for feature in sorted_features[:i]]\n","                best_performance_for_features = 0\n","                best_threshold_for_features = None\n","\n","                for threshold in thresholds:\n","                    fold_f1_scores = []\n","\n","                    # Perform LOOCV prediction with the selected features and model\n","                    for train_index, test_index in loo.split(X):\n","                        X_train, X_test = X.iloc[train_index][selected_features], X.iloc[test_index][selected_features]\n","                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                        # Use the appropriate model for prediction\n","                        if ml_model_name == 'XGBoost':\n","                            model = xgb.XGBClassifier(n_estimators=300, use_label_encoder=False, eval_metric='logloss', random_state=42)\n","                        elif ml_model_name == 'RandomForest':\n","                            model = RandomForestClassifier(n_estimators=300, random_state=42)\n","                        else:\n","                            model = ElasticNetCV(cv=5, max_iter=10000, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7)\n","\n","                        # Fit the model, make predictions and compute F1 score for the current fold\n","                        model.fit(X_train, y_train)\n","                        test_prediction = (model.predict(X_test) >= threshold).astype(int) if ml_model_name == 'ElasticNet' else (model.predict_proba(X_test)[:, 1] >= threshold).astype(int)\n","                        f1_score_current = f1_score(y_test, test_prediction, average='macro')\n","                        fold_f1_scores.append(f1_score_current)\n","\n","                    # Calculate the average F1 score for the current threshold\n","                    f1_score_avg = np.mean(fold_f1_scores)\n","\n","                    # Record the best performance and threshold for the features\n","                    if f1_score_avg > best_performance_for_features:\n","                        best_performance_for_features = f1_score_avg\n","                        best_threshold_for_features = threshold\n","\n","                # Update the best overall performance if it improves\n","                if best_performance_for_features > best_overall_performance:\n","                    best_overall_performance = best_performance_for_features\n","                    best_overall_setup = {\n","                        'features': selected_features,\n","                        'threshold': best_threshold_for_features,\n","                        'performance': best_performance_for_features,\n","                        'feature_selection_method': feature_selector_name,\n","                        'ml_model': ml_model_name\n","                    }\n","\n","            return {\n","                'feature_selection_method': best_overall_setup['feature_selection_method'],\n","                'ml_model': best_overall_setup['ml_model'],\n","                'best_features': best_overall_setup['features'],\n","                'features_length': len(best_overall_setup['features']),\n","                'best_threshold': best_overall_setup['threshold'],\n","                'best_performance': best_overall_setup['performance']\n","            }\n","\n","        # Process combinations of feature selection and prediction models\n","        combinations = [('LASSO', 'ElasticNet'), ('ElasticNet', 'ElasticNet'), ('LASSO', 'XGBoost'), ('ElasticNet', 'XGBoost')]\n","        results_per_combination = [process_combination(fs, ml) for fs, ml in combinations]\n","        best_combination = max(results_per_combination, key=lambda x: x['best_performance'] if x is not None else 0)\n","\n","        return time_point, best_combination\n","\n","    # Process time points within the specified range (before 15 months)\n","    time_points = np.sort(data['timepoint_numeric'].unique())\n","    results_parallel = Parallel(n_jobs=-1)(delayed(process_time_point)(tp) for tp in time_points)\n","    results = {tp: result for tp, result in results_parallel if result is not None}\n","\n","    return results\n","\n","# Evaluate the model\n","results_early_late = evaluate_models(celiac_data)\n","\n","# Print results\n","print(\"Results for Early Onset vs. Late Onset Prediction:\")\n","for time_point, res in results_early_late.items():\n","    if res is not None:\n","        print(f\"Time Point: {time_point}\")\n","        print(f\"  Feature Selection Method: {res['feature_selection_method']}\")\n","        print(f\"  Machine Learning Model: {res['ml_model']}\")\n","        print(f\"  Best F1 Score: {res['best_performance']}\")\n","        print(f\"  Best Threshold: {res['best_threshold']}\")\n","        print(f\"  Features Used: {res['best_features']}\")\n","        print(f\"  Features Length: {res['features_length']}\")\n","        print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","# Filter data to include only relative time points from -18 to onset\n","filtered_data = combined_data_filtered[(combined_data_filtered['Relative_timepoint'] >= -18) & (combined_data_filtered['Relative_timepoint'] <= 0)]\n","\n","# Define selected features for each time point\n","features_timepoint_18 = [\n","    'Candidatus_Cibionibacter_quicibialis', 'Anaerobutyricum_soehngenii', 'Clostridium_SGB6173', 'Bacteroides_ovatus', \n","    'Bifidobacterium_adolescentis', 'Dysosmobacter_welbionis', 'Bacteroides_fragilis', 'Bifidobacterium_catenulatum', \n","    'Bifidobacterium_pseudocatenulatum', 'Blautia_wexlerae', 'Clostridiales_bacterium_KLE1615', 'Bacteroides_thetaiotaomicron', \n","    'Coprococcus_comes', 'Eisenbergiella_tayi', 'Bacteroides_stercoris', 'Lachnospiraceae_bacterium', 'Escherichia_coli', \n","    'Roseburia_faecis', 'Mediterraneibacter_faecis', 'Phascolarctobacterium_faecium', 'Flavonifractor_plautii', \n","    'Roseburia_intestinalis', 'Anaerobutyricum_hallii', 'Bacteroides_cellulosilyticus', 'Roseburia_sp_AF02_12', \n","    'Clostridium_sp_AM33_3', 'Lachnospira_eligens', 'Clostridium_SGB6179', 'Ruminococcus_torques', 'Ruminococcus_callidus', \n","    'Streptococcus_thermophilus', 'FUCCAT-PWY: fucose degradation', 'P125-PWY: superpathway of (R,R)-butanediol biosynthesis', \n","    'FUC-RHAMCAT-PWY: superpathway of fucose and rhamnose degradation', 'POLYAMSYN-PWY: superpathway of polyamine biosynthesis I', \n","    'ARG+POLYAMINE-SYN: superpathway of arginine and polyamine biosynthesis', 'KETOGLUCONMET-PWY: ketogluconate metabolism', \n","    'METH-ACETATE-PWY: methanogenesis from acetate', 'GALACTARDEG-PWY: D-galactarate degradation I', \n","    'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', 'PWY-5367: petroselinate biosynthesis', \n","    'PWY-5022: 4-aminobutanoate degradation V', 'GLUCUROCAT-PWY: superpathway of &beta;-D-glucuronosides degradation', \n","    'BIOTIN-BIOSYNTHESIS-PWY: biotin biosynthesis I'\n","]\n","\n","features_timepoint_15 = [\n","    'Bacteroides_thetaiotaomicron', 'Bifidobacterium_bifidum', 'Anaerobutyricum_hallii', 'Bifidobacterium_adolescentis', \n","    'Bifidobacterium_pseudocatenulatum', 'Alistipes_onderdonkii', 'Alistipes_putredinis', 'Akkermansia_muciniphila', \n","    'Clostridiaceae_bacterium_Marseille_Q3526', 'KETOGLUCONMET-PWY: ketogluconate metabolism', 'PPGPPMET-PWY: ppGpp metabolism', \n","    'P105-PWY: TCA cycle IV (2-oxoglutarate decarboxylase)', 'GALACTITOLCAT-PWY: galactitol degradation'\n","]\n","features_timepoint_12 = [\n","    'Anaerobutyricum_hallii', 'GGB9469_SGB14862', 'Dialister_invisus', 'Alistipes_finegoldii', 'Alistipes_onderdonkii', \n","    'Enterocloster_bolteae', 'GGB3740_SGB5076', 'Enterococcus_faecium', 'Eggerthella_lenta', 'Alistipes_putredinis', \n","    'Bacteroides_stercoris', 'Blautia_wexlerae', 'Bacteroides_fragilis', 'Enterocloster_clostridioformis', \n","    'Intestinibacter_bartlettii', 'Anaerostipes_hadrus', 'PWY-5130: 2-oxobutanoate degradation I', \n","    'PWY-5690: TCA cycle II (plants and fungi)', 'ALLANTOINDEG-PWY: superpathway of allantoin degradation in yeast', \n","    'PWY-6163: chorismate biosynthesis from 3-dehydroquinate', 'P108-PWY: pyruvate fermentation to propanoate I', \n","    'P4-PWY: superpathway of L-lysine, L-threonine and L-methionine biosynthesis I', \n","    'COA-PWY-1: superpathway of coenzyme A biosynthesis III (mammals)', \n","    'GOLPDLCAT-PWY: superpathway of glycerol degradation to 1,3-propanediol', 'PPGPPMET-PWY: ppGpp metabolism', \n","    'FASYN-INITIAL-PWY: superpathway of fatty acid biosynthesis initiation (E. coli)', \n","    'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)', \n","    'PWY-6121: 5-aminoimidazole ribonucleotide biosynthesis I', \n","    'PEPTIDOGLYCANSYN-PWY: peptidoglycan biosynthesis I (meso-diaminopimelate containing)', \n","    'COMPLETE-ARO-PWY: superpathway of aromatic amino acid biosynthesis', \n","    'METHGLYUT-PWY: superpathway of methylglyoxal degradation', 'PWY-3841: folate transformations II (plants)', \n","    'P23-PWY: reductive TCA cycle I', 'PWY-241: C4 photosynthetic carbon assimilation cycle, NADP-ME type', \n","    'HISTSYN-PWY: L-histidine biosynthesis', \n","    'GLYCOLYSIS-TCA-GLYOX-BYPASS: superpathway of glycolysis, pyruvate dehydrogenase, TCA, and glyoxylate bypass', \n","    'PWY-1861: formaldehyde assimilation II (assimilatory RuMP Cycle)'\n","]\n","\n","features_timepoint_9 = [\n","    'Bacteroides_ovatus', 'Bifidobacterium_catenulatum', 'Clostridiales_bacterium', 'Bifidobacterium_adolescentis', \n","    'Blautia_wexlerae', 'Candidatus_Cibionibacter_quicibialis', 'Clostridium_SGB6173', 'Bacteroides_thetaiotaomicron', \n","    'Bacteroides_xylanisolvens', 'Dialister_invisus', 'Bacteroides_uniformis', 'HSERMETANA-PWY: L-methionine biosynthesis III', \n","    'COMPLETE-ARO-PWY: superpathway of aromatic amino acid biosynthesis', \n","    'HCAMHPDEG-PWY: 3-phenylpropanoate and 3-(3-hydroxyphenyl)propanoate degradation to 2-hydroxypentadienoate', \n","    'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', 'DAPLYSINESYN-PWY: L-lysine biosynthesis I', \n","    'GALACT-GLUCUROCAT-PWY: superpathway of hexuronide and hexuronate degradation', \n","    'NAGLIPASYN-PWY: lipid IVA biosynthesis (E. coli)', 'FOLSYN-PWY: superpathway of tetrahydrofolate biosynthesis and salvage', \n","    'GOLPDLCAT-PWY: superpathway of glycerol degradation to 1,3-propanediol', \n","    'ARGSYNBSUB-PWY: L-arginine biosynthesis II (acetyl cycle)', \n","    'PRPP-PWY: superpathway of histidine, purine, and pyrimidine biosynthesis'\n","]\n","features_timepoint_6 = [\n","    'GGB9480_SGB14874', 'Faecalibacillus_intestinalis', 'Alistipes_putredinis', 'Brotolimicola_acetigignens', \n","    'Dorea_formicigenerans', 'Anaerostipes_hadrus', 'Eisenbergiella_massiliensis', 'Phascolarctobacterium_faecium', \n","    'Bacteroides_thetaiotaomicron', 'Clostridiales_bacterium_KLE1615', 'Blautia_hansenii', 'Roseburia_hominis', \n","    'Enterococcus_faecalis', 'Clostridium_saudiense', 'Bifidobacterium_longum', 'Bifidobacterium_dentium', \n","    'Streptococcus_thermophilus', 'PWY-6606: guanosine nucleotides degradation II', \n","    'PWY-6353: purine nucleotides degradation II (aerobic)'\n","]\n","\n","features_timepoint_3 = [\n","    'Gemmiger_formicilis', 'Lachnospira_pectinoschiza', 'Bacteroides_caccae', 'GGB3256_SGB4303', 'Romboutsia_timonensis', \n","    'Parabacteroides_merdae', 'Enterococcus_faecium', 'Enterococcus_faecalis', 'Clostridium_sp_C5_48', 'Phocaeicola_vulgatus', \n","    'Clostridium_SGB6173', 'Escherichia_coli', 'Roseburia_faecis', 'Dorea_longicatena', 'Bifidobacterium_bifidum', \n","    'Bifidobacterium_catenulatum', 'Bifidobacterium_animalis', 'Roseburia_intestinalis', 'Tyzzerella_nexilis', \n","    'Veillonella_ratti', 'P185-PWY: formaldehyde assimilation III (dihydroxyacetone cycle)', \n","    'PWY-5180: toluene degradation I (aerobic) (via o-cresol)', \n","    'PROPFERM-PWY: superpathway of L-alanine fermentation (Stickland reaction)', \n","    'PWY-5138: fatty acid &beta;-oxidation IV (unsaturated, even number)', \n","    'GLYCOLYSIS-TCA-GLYOX-BYPASS: superpathway of glycolysis, pyruvate dehydrogenase, TCA, and glyoxylate bypass', \n","    \"PWY-6123: inosine-5'-phosphate biosynthesis I\", 'CENTFERM-PWY: pyruvate fermentation to butanoate', \n","    'PWY-6285: superpathway of fatty acids biosynthesis (E. coli)', \"PWY-6124: inosine-5'-phosphate biosynthesis II\", \n","    'PWY-1861: formaldehyde assimilation II (assimilatory RuMP Cycle)', \n","    'ASPASN-PWY: superpathway of L-aspartate and L-asparagine biosynthesis', \n","    'PWY-6470: peptidoglycan biosynthesis V (&beta;-lactam resistance)', \n","    'COLANSYN-PWY: colanic acid building blocks biosynthesis', 'DTDPRHAMSYN-PWY: dTDP-&beta;-L-rhamnose biosynthesis'\n","]\n","features_timepoint_0 = [\n","    'Eubacterium_siraeum', 'Eisenbergiella_massiliensis', 'Alistipes_putredinis', 'Clostridium_SGB6179', 'Enterocloster_bolteae', \n","    'GGB9469_SGB14862', 'GGB51647_SGB4348', 'GGB9480_SGB14874', 'Clostridiales_bacterium_KLE1615', \n","    'Erysipelatoclostridium_ramosum', 'Alistipes_onderdonkii', 'Parasutterella_excrementihominis', \n","    'Fusicatenibacter_saccharivorans', 'Blautia_wexlerae', 'Bifidobacterium_pseudocatenulatum', 'Parabacteroides_distasonis', \n","    'Bifidobacterium_adolescentis', 'Bifidobacterium_longum', 'Phocaeicola_vulgatus', 'GGB3256_SGB4303', \n","    'Clostridiaceae_bacterium', 'Roseburia_faecis', 'Lacrimispora_amygdalina', 'GGB4456_SGB6141', 'Blautia_obeum', \n","    'Anaerostipes_hadrus', 'Bifidobacterium_breve', 'Candidatus_Cibionibacter_quicibialis', 'Brotolimicola_acetigignens', \n","    'Roseburia_intestinalis', 'Enterococcus_faecalis', 'Blautia_faecis', 'Clostridium_leptum', 'Clostridium_sp_AT4', \n","    'Clostridium_SGB4750', 'Coprococcus_eutactus', 'GGB9534_SGB14937', 'Intestinimonas_butyriciproducens', \n","    'Lachnospira_sp_NSJ_43', 'Clostridium_sp_C5_48', 'Fusicatenibacter_sp_CLA_AA_H277', 'Clostridium_sp_AM22_11AC', \n","    'Anaerostipes_caccae', 'Pseudoflavonifractor_capillosus', 'Roseburia_hominis', 'Ruminococcus_bromii', \n","    'Oscillibacter_valericigenes', 'Flavonifractor_plautii', 'Ruminococcus_gnavus', 'PWY-4041: &gamma;-glutamyl cycle', \n","    'PWY-6549: L-glutamine biosynthesis III', 'FUC-RHAMCAT-PWY: superpathway of fucose and rhamnose degradation', \n","    'PWY-5677: succinate fermentation to butanoate', 'P163-PWY: L-lysine fermentation to acetate and butanoate'\n","]\n","\n","# Define a function to evaluate combinations of feature selectors and models\n","def evaluate_models(data):\n","    results = {}\n","\n","    # Define a function to process each time point independently\n","    def process_time_point(time_point):\n","        print(f\"Processing relative time point: {time_point}\")\n","\n","        # Select features based on the time point\n","        if time_point == -18:\n","            selected_features = features_timepoint_18\n","        elif time_point == -15:\n","            selected_features = features_timepoint_15\n","        elif time_point == -12:\n","            selected_features = features_timepoint_12\n","        elif time_point == -9:\n","            selected_features = features_timepoint_9\n","        elif time_point == -6:\n","            selected_features = features_timepoint_6\n","        elif time_point == -3:\n","            selected_features = features_timepoint_3\n","        elif time_point == 0:\n","            selected_features = features_timepoint_0\n","        else:\n","            print(f\"No predefined features for time point {time_point}.\")\n","            return time_point, None\n","\n","        # Filter data for the current relative time point and extract selected features\n","        current_data = data[data['Relative_timepoint'] == time_point]\n","        X = current_data[selected_features] # Feature matrix\n","        y = current_data['Diagnosis'] # Labels\n","\n","        # Ensure there are enough samples to perform LOOCV\n","        if len(y) < 2:\n","            print(f\"Skipping relative time point {time_point} due to insufficient samples.\")\n","            return time_point, None\n","\n","        # Initialize Leave-One-Out cross-validation\n","        loo = LeaveOneOut()\n","        best_overall_score = 0\n","        best_overall_setup = {}\n","\n","        # Define a function to process each feature selector and model combination\n","        def process_combination(feature_selector_name, ml_model_name):\n","            all_selected_features = []\n","            all_importances = []\n","\n","            # Loop through the training/test splits generated by LOOCV\n","            for train_index, test_index in loo.split(X):\n","                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                # Perform feature selection based on the specified selector\n","                if feature_selector_name == 'LASSO':\n","                    feature_selector = LassoCV(cv=loo, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30)).fit(X_train, y_train)\n","                else:\n","                    feature_selector = ElasticNetCV(cv=loo, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7).fit(X_train, y_train)\n","\n","                # Select features with non-zero coefficients\n","                selected_features = X_train.columns[feature_selector.coef_ != 0]\n","                selected_features = selected_features[:min(len(selected_features), int(0.8 * len(y_train)))]\n","\n","                # If no features are selected, skip this iteration\n","                if len(selected_features) == 0:\n","                    continue\n","\n","                # Select the relevant features from the training set\n","                X_train_selected = X_train[selected_features]\n","\n","                # Perform logistic regression for ranking the selected features based on importance\n","                logistic = LogisticRegression(max_iter=10000, random_state=42, solver='liblinear').fit(X_train_selected, y_train)\n","                importances = abs(logistic.coef_[0])\n","                ranked_features = sorted(zip(selected_features, importances), key=lambda x: x[1], reverse=True)\n","\n","                # Store selected features and their importance\n","                all_selected_features.extend([f[0] for f in ranked_features])\n","                all_importances.extend([f[1] for f in ranked_features])\n","\n","            # If no features were selected across all folds, return None\n","            if not all_selected_features:\n","                return None\n","\n","            # Aggregate selected features across all folds\n","            unique_features = list(set(all_selected_features))\n","            frequency = Counter(all_selected_features)\n","            avg_importance = {feature: np.mean([imp for feat, imp in zip(all_selected_features, all_importances) if feat == feature])\n","                              for feature in unique_features}\n","\n","            # Calculate a composite score for each feature based on frequency and importance\n","            composite_scores = {feature: 0.5 * (frequency[feature] / loo.get_n_splits(X)) + 0.5 * (avg_importance[feature] / sum(avg_importance.values()))\n","                                for feature in unique_features}\n","            sorted_features = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","            # Evaluate different feature subsets with varying thresholds\n","            best_overall_performance = 0\n","            best_overall_setup = {}\n","            best_percentage = 0\n","            thresholds = np.linspace(0.05, 0.95, 19)\n","\n","            for i in range(1, min(len(sorted_features), int(0.8 * len(y))) + 1):\n","                selected_features = [feature[0] for feature in sorted_features[:i]]\n","                best_performance_for_features = 0\n","                best_threshold_for_features = None\n","\n","                for threshold in thresholds:\n","                    fold_f1_scores = []\n","\n","                    # Perform LOOCV prediction with the selected features and model\n","                    for train_index, test_index in loo.split(X):\n","                        X_train, X_test = X.iloc[train_index][selected_features], X.iloc[test_index][selected_features]\n","                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                        # Use the appropriate model for prediction\n","                        if ml_model_name == 'XGBoost':\n","                            model = xgb.XGBClassifier(n_estimators=300, use_label_encoder=False, eval_metric='logloss', random_state=42)\n","                        elif ml_model_name == 'RandomForest':\n","                            model = RandomForestClassifier(n_estimators=300, random_state=42)\n","                        else:\n","                            model = ElasticNetCV(cv=5, max_iter=10000, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7)\n","\n","                        # Fit the model, make predictions and compute F1 score for the current fold\n","                        model.fit(X_train, y_train)\n","                        test_prediction = (model.predict(X_test) >= threshold).astype(int) if ml_model_name == 'ElasticNet' else (model.predict_proba(X_test)[:, 1] >= threshold).astype(int)\n","                        f1_score_current = f1_score(y_test, test_prediction, average='macro')\n","                        fold_f1_scores.append(f1_score_current)\n","\n","                    # Calculate the average F1 score for the current threshold\n","                    f1_score_avg = np.mean(fold_f1_scores)\n","\n","                    # Record the best performance and threshold for the features\n","                    if f1_score_avg > best_performance_for_features:\n","                        best_performance_for_features = f1_score_avg\n","                        best_threshold_for_features = threshold\n","\n","                # Update the best overall performance if it improves\n","                if best_performance_for_features > best_overall_performance:\n","                    best_overall_performance = best_performance_for_features\n","                    best_overall_setup = {\n","                        'features': selected_features,\n","                        'threshold': best_threshold_for_features,\n","                        'performance': best_performance_for_features,\n","                        'feature_selection_method': feature_selector_name,\n","                        'ml_model': ml_model_name\n","                    }\n","\n","            return {\n","                'feature_selection_method': best_overall_setup['feature_selection_method'],\n","                'ml_model': best_overall_setup['ml_model'],\n","                'best_features': best_overall_setup['features'],\n","                'features_length': len(best_overall_setup['features']),\n","                'best_threshold': best_overall_setup['threshold'],\n","                'best_performance': best_overall_setup['performance']\n","            }\n","\n","        # Process combinations of feature selection and prediction models\n","        combinations = [('LASSO', 'ElasticNet'), ('ElasticNet', 'ElasticNet')]\n","        results_per_combination = [process_combination(fs, ml) for fs, ml in combinations]\n","        best_combination = max(results_per_combination, key=lambda x: x['best_performance'] if x is not None else 0)\n","\n","        return time_point, best_combination\n","\n","    # Process relative time points within the specified range\n","    time_points = np.sort(data['Relative_timepoint'].unique())\n","    results_parallel = Parallel(n_jobs=-1)(delayed(process_time_point)(tp) for tp in time_points)\n","    results = {tp: result for tp, result in results_parallel if result is not None}\n","\n","    return results\n","\n","# Evaluate the model\n","results_relative = evaluate_models(filtered_data)\n","\n","# Print results\n","print(\"Results for Celiac Disease Prediction by Relative Time Point:\")\n","for time_point, res in results_relative.items():\n","    if res is not None:\n","        print(f\"Relative Time Point: {time_point}\")\n","        print(f\"  Feature Selection Method: {res['feature_selection_method']}\")\n","        print(f\"  Machine Learning Model: {res['ml_model']}\")\n","        print(f\"  Best F1 Score: {res['best_performance']}\")\n","        print(f\"  Best Threshold: {res['best_threshold']}\")\n","        print(f\"  Features Used: {res['best_features']}\")\n","        print(f\"  Features Length: {res['features_length']}\")\n","        print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","# Filter data to include only relative time points from -18 to onset\n","filtered_data = combined_data_filtered[(combined_data_filtered['Relative_timepoint'] >= -18) & (combined_data_filtered['Relative_timepoint'] <= 0)]\n","\n","# Define selected features for each time point\n","features_timepoint_18 = [\n","    'Candidatus_Cibionibacter_quicibialis', 'Anaerobutyricum_soehngenii', 'Clostridium_SGB6173', 'Bacteroides_ovatus', \n","    'Bifidobacterium_adolescentis', 'Dysosmobacter_welbionis', 'Bacteroides_fragilis', 'Bifidobacterium_catenulatum', \n","    'Bifidobacterium_pseudocatenulatum', 'Blautia_wexlerae', 'Clostridiales_bacterium_KLE1615', 'Bacteroides_thetaiotaomicron', \n","    'Coprococcus_comes', 'Eisenbergiella_tayi', 'Bacteroides_stercoris', 'Lachnospiraceae_bacterium', 'Escherichia_coli', \n","    'Roseburia_faecis', 'Mediterraneibacter_faecis', 'Phascolarctobacterium_faecium', 'Flavonifractor_plautii', \n","    'Roseburia_intestinalis', 'Anaerobutyricum_hallii', 'Bacteroides_cellulosilyticus', 'Roseburia_sp_AF02_12', \n","    'Clostridium_sp_AM33_3', 'Lachnospira_eligens', 'Clostridium_SGB6179', 'Ruminococcus_torques', 'Ruminococcus_callidus', \n","    'Streptococcus_thermophilus', 'FUCCAT-PWY: fucose degradation', 'P125-PWY: superpathway of (R,R)-butanediol biosynthesis', \n","    'FUC-RHAMCAT-PWY: superpathway of fucose and rhamnose degradation', 'POLYAMSYN-PWY: superpathway of polyamine biosynthesis I', \n","    'ARG+POLYAMINE-SYN: superpathway of arginine and polyamine biosynthesis', 'KETOGLUCONMET-PWY: ketogluconate metabolism', \n","    'METH-ACETATE-PWY: methanogenesis from acetate', 'GALACTARDEG-PWY: D-galactarate degradation I', \n","    'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', 'PWY-5367: petroselinate biosynthesis', \n","    'PWY-5022: 4-aminobutanoate degradation V', 'GLUCUROCAT-PWY: superpathway of &beta;-D-glucuronosides degradation', \n","    'BIOTIN-BIOSYNTHESIS-PWY: biotin biosynthesis I'\n","]\n","\n","features_timepoint_15 = [\n","    'Bacteroides_thetaiotaomicron', 'Bifidobacterium_bifidum', 'Anaerobutyricum_hallii', 'Bifidobacterium_adolescentis', \n","    'Bifidobacterium_pseudocatenulatum', 'Alistipes_onderdonkii', 'Alistipes_putredinis', 'Akkermansia_muciniphila', \n","    'Clostridiaceae_bacterium_Marseille_Q3526', 'KETOGLUCONMET-PWY: ketogluconate metabolism', 'PPGPPMET-PWY: ppGpp metabolism', \n","    'P105-PWY: TCA cycle IV (2-oxoglutarate decarboxylase)', 'GALACTITOLCAT-PWY: galactitol degradation'\n","]\n","features_timepoint_12 = [\n","    'Anaerobutyricum_hallii', 'GGB9469_SGB14862', 'Dialister_invisus', 'Alistipes_finegoldii', 'Alistipes_onderdonkii', \n","    'Enterocloster_bolteae', 'GGB3740_SGB5076', 'Enterococcus_faecium', 'Eggerthella_lenta', 'Alistipes_putredinis', \n","    'Bacteroides_stercoris', 'Blautia_wexlerae', 'Bacteroides_fragilis', 'Enterocloster_clostridioformis', \n","    'Intestinibacter_bartlettii', 'Anaerostipes_hadrus', 'PWY-5130: 2-oxobutanoate degradation I', \n","    'PWY-5690: TCA cycle II (plants and fungi)', 'ALLANTOINDEG-PWY: superpathway of allantoin degradation in yeast', \n","    'PWY-6163: chorismate biosynthesis from 3-dehydroquinate', 'P108-PWY: pyruvate fermentation to propanoate I', \n","    'P4-PWY: superpathway of L-lysine, L-threonine and L-methionine biosynthesis I', \n","    'COA-PWY-1: superpathway of coenzyme A biosynthesis III (mammals)', \n","    'GOLPDLCAT-PWY: superpathway of glycerol degradation to 1,3-propanediol', 'PPGPPMET-PWY: ppGpp metabolism', \n","    'FASYN-INITIAL-PWY: superpathway of fatty acid biosynthesis initiation (E. coli)', \n","    'HEXITOLDEGSUPER-PWY: superpathway of hexitol degradation (bacteria)', \n","    'PWY-6121: 5-aminoimidazole ribonucleotide biosynthesis I', \n","    'PEPTIDOGLYCANSYN-PWY: peptidoglycan biosynthesis I (meso-diaminopimelate containing)', \n","    'COMPLETE-ARO-PWY: superpathway of aromatic amino acid biosynthesis', \n","    'METHGLYUT-PWY: superpathway of methylglyoxal degradation', 'PWY-3841: folate transformations II (plants)', \n","    'P23-PWY: reductive TCA cycle I', 'PWY-241: C4 photosynthetic carbon assimilation cycle, NADP-ME type', \n","    'HISTSYN-PWY: L-histidine biosynthesis', \n","    'GLYCOLYSIS-TCA-GLYOX-BYPASS: superpathway of glycolysis, pyruvate dehydrogenase, TCA, and glyoxylate bypass', \n","    'PWY-1861: formaldehyde assimilation II (assimilatory RuMP Cycle)'\n","]\n","\n","features_timepoint_9 = [\n","    'Bacteroides_ovatus', 'Bifidobacterium_catenulatum', 'Clostridiales_bacterium', 'Bifidobacterium_adolescentis', \n","    'Blautia_wexlerae', 'Candidatus_Cibionibacter_quicibialis', 'Clostridium_SGB6173', 'Bacteroides_thetaiotaomicron', \n","    'Bacteroides_xylanisolvens', 'Dialister_invisus', 'Bacteroides_uniformis', 'HSERMETANA-PWY: L-methionine biosynthesis III', \n","    'COMPLETE-ARO-PWY: superpathway of aromatic amino acid biosynthesis', \n","    'HCAMHPDEG-PWY: 3-phenylpropanoate and 3-(3-hydroxyphenyl)propanoate degradation to 2-hydroxypentadienoate', \n","    'POLYISOPRENSYN-PWY: polyisoprenoid biosynthesis (E. coli)', 'DAPLYSINESYN-PWY: L-lysine biosynthesis I', \n","    'GALACT-GLUCUROCAT-PWY: superpathway of hexuronide and hexuronate degradation', \n","    'NAGLIPASYN-PWY: lipid IVA biosynthesis (E. coli)', 'FOLSYN-PWY: superpathway of tetrahydrofolate biosynthesis and salvage', \n","    'GOLPDLCAT-PWY: superpathway of glycerol degradation to 1,3-propanediol', \n","    'ARGSYNBSUB-PWY: L-arginine biosynthesis II (acetyl cycle)', \n","    'PRPP-PWY: superpathway of histidine, purine, and pyrimidine biosynthesis'\n","]\n","features_timepoint_6 = [\n","    'GGB9480_SGB14874', 'Faecalibacillus_intestinalis', 'Alistipes_putredinis', 'Brotolimicola_acetigignens', \n","    'Dorea_formicigenerans', 'Anaerostipes_hadrus', 'Eisenbergiella_massiliensis', 'Phascolarctobacterium_faecium', \n","    'Bacteroides_thetaiotaomicron', 'Clostridiales_bacterium_KLE1615', 'Blautia_hansenii', 'Roseburia_hominis', \n","    'Enterococcus_faecalis', 'Clostridium_saudiense', 'Bifidobacterium_longum', 'Bifidobacterium_dentium', \n","    'Streptococcus_thermophilus', 'PWY-6606: guanosine nucleotides degradation II', \n","    'PWY-6353: purine nucleotides degradation II (aerobic)'\n","]\n","\n","features_timepoint_3 = [\n","    'Gemmiger_formicilis', 'Lachnospira_pectinoschiza', 'Bacteroides_caccae', 'GGB3256_SGB4303', 'Romboutsia_timonensis', \n","    'Parabacteroides_merdae', 'Enterococcus_faecium', 'Enterococcus_faecalis', 'Clostridium_sp_C5_48', 'Phocaeicola_vulgatus', \n","    'Clostridium_SGB6173', 'Escherichia_coli', 'Roseburia_faecis', 'Dorea_longicatena', 'Bifidobacterium_bifidum', \n","    'Bifidobacterium_catenulatum', 'Bifidobacterium_animalis', 'Roseburia_intestinalis', 'Tyzzerella_nexilis', \n","    'Veillonella_ratti', 'P185-PWY: formaldehyde assimilation III (dihydroxyacetone cycle)', \n","    'PWY-5180: toluene degradation I (aerobic) (via o-cresol)', \n","    'PROPFERM-PWY: superpathway of L-alanine fermentation (Stickland reaction)', \n","    'PWY-5138: fatty acid &beta;-oxidation IV (unsaturated, even number)', \n","    'GLYCOLYSIS-TCA-GLYOX-BYPASS: superpathway of glycolysis, pyruvate dehydrogenase, TCA, and glyoxylate bypass', \n","    \"PWY-6123: inosine-5'-phosphate biosynthesis I\", 'CENTFERM-PWY: pyruvate fermentation to butanoate', \n","    'PWY-6285: superpathway of fatty acids biosynthesis (E. coli)', \"PWY-6124: inosine-5'-phosphate biosynthesis II\", \n","    'PWY-1861: formaldehyde assimilation II (assimilatory RuMP Cycle)', \n","    'ASPASN-PWY: superpathway of L-aspartate and L-asparagine biosynthesis', \n","    'PWY-6470: peptidoglycan biosynthesis V (&beta;-lactam resistance)', \n","    'COLANSYN-PWY: colanic acid building blocks biosynthesis', 'DTDPRHAMSYN-PWY: dTDP-&beta;-L-rhamnose biosynthesis'\n","]\n","features_timepoint_0 = [\n","    'Eubacterium_siraeum', 'Eisenbergiella_massiliensis', 'Alistipes_putredinis', 'Clostridium_SGB6179', 'Enterocloster_bolteae', \n","    'GGB9469_SGB14862', 'GGB51647_SGB4348', 'GGB9480_SGB14874', 'Clostridiales_bacterium_KLE1615', \n","    'Erysipelatoclostridium_ramosum', 'Alistipes_onderdonkii', 'Parasutterella_excrementihominis', \n","    'Fusicatenibacter_saccharivorans', 'Blautia_wexlerae', 'Bifidobacterium_pseudocatenulatum', 'Parabacteroides_distasonis', \n","    'Bifidobacterium_adolescentis', 'Bifidobacterium_longum', 'Phocaeicola_vulgatus', 'GGB3256_SGB4303', \n","    'Clostridiaceae_bacterium', 'Roseburia_faecis', 'Lacrimispora_amygdalina', 'GGB4456_SGB6141', 'Blautia_obeum', \n","    'Anaerostipes_hadrus', 'Bifidobacterium_breve', 'Candidatus_Cibionibacter_quicibialis', 'Brotolimicola_acetigignens', \n","    'Roseburia_intestinalis', 'Enterococcus_faecalis', 'Blautia_faecis', 'Clostridium_leptum', 'Clostridium_sp_AT4', \n","    'Clostridium_SGB4750', 'Coprococcus_eutactus', 'GGB9534_SGB14937', 'Intestinimonas_butyriciproducens', \n","    'Lachnospira_sp_NSJ_43', 'Clostridium_sp_C5_48', 'Fusicatenibacter_sp_CLA_AA_H277', 'Clostridium_sp_AM22_11AC', \n","    'Anaerostipes_caccae', 'Pseudoflavonifractor_capillosus', 'Roseburia_hominis', 'Ruminococcus_bromii', \n","    'Oscillibacter_valericigenes', 'Flavonifractor_plautii', 'Ruminococcus_gnavus', 'PWY-4041: &gamma;-glutamyl cycle', \n","    'PWY-6549: L-glutamine biosynthesis III', 'FUC-RHAMCAT-PWY: superpathway of fucose and rhamnose degradation', \n","    'PWY-5677: succinate fermentation to butanoate', 'P163-PWY: L-lysine fermentation to acetate and butanoate'\n","]\n","\n","# Define a function to evaluate combinations of feature selectors and models\n","def evaluate_models(data):\n","    results = {}\n","\n","    # Define a function to process each time point independently\n","    def process_time_point(time_point):\n","        print(f\"Processing relative time point: {time_point}\")\n","\n","        # Select features based on the time point\n","        if time_point == -18:\n","            selected_features = features_timepoint_18\n","        elif time_point == -15:\n","            selected_features = features_timepoint_15\n","        elif time_point == -12:\n","            selected_features = features_timepoint_12\n","        elif time_point == -9:\n","            selected_features = features_timepoint_9\n","        elif time_point == -6:\n","            selected_features = features_timepoint_6\n","        elif time_point == -3:\n","            selected_features = features_timepoint_3\n","        elif time_point == 0:\n","            selected_features = features_timepoint_0\n","        else:\n","            print(f\"No predefined features for time point {time_point}.\")\n","            return time_point, None\n","\n","        # Filter data for the current relative time point and extract selected features\n","        current_data = data[data['Relative_timepoint'] == time_point]\n","        X = current_data[selected_features] # Feature matrix\n","        y = current_data['Diagnosis'] # Labels\n","\n","        # Ensure there are enough samples to perform LOOCV\n","        if len(y) < 2:\n","            print(f\"Skipping relative time point {time_point} due to insufficient samples.\")\n","            return time_point, None\n","\n","        # Initialize Leave-One-Out cross-validation\n","        loo = LeaveOneOut()\n","        best_overall_score = 0\n","        best_overall_setup = {}\n","\n","        # Define a function to process each feature selector and model combination\n","        def process_combination(feature_selector_name, ml_model_name):\n","            all_selected_features = []\n","            all_importances = []\n","\n","            # Loop through the training/test splits generated by LOOCV\n","            for train_index, test_index in loo.split(X):\n","                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                # Perform feature selection based on the specified selector\n","                if feature_selector_name == 'LASSO':\n","                    feature_selector = LassoCV(cv=loo, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30)).fit(X_train, y_train)\n","                else:\n","                    feature_selector = ElasticNetCV(cv=loo, max_iter=20000, tol=1e-4, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7).fit(X_train, y_train)\n","\n","                # Select features with non-zero coefficients\n","                selected_features = X_train.columns[feature_selector.coef_ != 0]\n","                selected_features = selected_features[:min(len(selected_features), int(0.8 * len(y_train)))]\n","\n","                # If no features are selected, skip this iteration\n","                if len(selected_features) == 0:\n","                    continue\n","\n","                # Select the relevant features from the training set\n","                X_train_selected = X_train[selected_features]\n","\n","                # Perform logistic regression for ranking the selected features based on importance\n","                logistic = LogisticRegression(max_iter=10000, random_state=42, solver='liblinear').fit(X_train_selected, y_train)\n","                importances = abs(logistic.coef_[0])\n","                ranked_features = sorted(zip(selected_features, importances), key=lambda x: x[1], reverse=True)\n","\n","                # Store selected features and their importance\n","                all_selected_features.extend([f[0] for f in ranked_features])\n","                all_importances.extend([f[1] for f in ranked_features])\n","\n","            # If no features were selected across all folds, return None\n","            if not all_selected_features:\n","                return None\n","\n","            # Aggregate selected features across all folds\n","            unique_features = list(set(all_selected_features))\n","            frequency = Counter(all_selected_features)\n","            avg_importance = {feature: np.mean([imp for feat, imp in zip(all_selected_features, all_importances) if feat == feature])\n","                              for feature in unique_features}\n","\n","            # Calculate a composite score for each feature based on frequency and importance\n","            composite_scores = {feature: 0.5 * (frequency[feature] / loo.get_n_splits(X)) + 0.5 * (avg_importance[feature] / sum(avg_importance.values()))\n","                                for feature in unique_features}\n","            sorted_features = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","            # Evaluate different feature subsets with varying thresholds\n","            best_overall_performance = 0\n","            best_overall_setup = {}\n","            best_percentage = 0\n","            thresholds = np.linspace(0.05, 0.95, 19)\n","\n","            for i in range(1, min(len(sorted_features), int(0.8 * len(y))) + 1):\n","                selected_features = [feature[0] for feature in sorted_features[:i]]\n","                best_performance_for_features = 0\n","                best_threshold_for_features = None\n","\n","                for threshold in thresholds:\n","                    fold_f1_scores = []\n","\n","                    # Perform LOOCV prediction with the selected features and model\n","                    for train_index, test_index in loo.split(X):\n","                        X_train, X_test = X.iloc[train_index][selected_features], X.iloc[test_index][selected_features]\n","                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","                        # Use the appropriate model for prediction\n","                        if ml_model_name == 'XGBoost':\n","                            model = xgb.XGBClassifier(n_estimators=300, use_label_encoder=False, eval_metric='logloss', random_state=42)\n","                        elif ml_model_name == 'RandomForest':\n","                            model = RandomForestClassifier(n_estimators=300, random_state=42)\n","                        else:\n","                            model = ElasticNetCV(cv=5, max_iter=10000, alphas=np.logspace(-6, -2, 30), l1_ratio=0.7)\n","\n","                        # Fit the model, make predictions and compute F1 score for the current fold\n","                        model.fit(X_train, y_train)\n","                        test_prediction = (model.predict(X_test) >= threshold).astype(int) if ml_model_name == 'ElasticNet' else (model.predict_proba(X_test)[:, 1] >= threshold).astype(int)\n","                        f1_score_current = f1_score(y_test, test_prediction, average='macro')\n","                        fold_f1_scores.append(f1_score_current)\n","\n","                    # Calculate the average F1 score for the current threshold\n","                    f1_score_avg = np.mean(fold_f1_scores)\n","\n","                    # Record the best performance and threshold for the features\n","                    if f1_score_avg > best_performance_for_features:\n","                        best_performance_for_features = f1_score_avg\n","                        best_threshold_for_features = threshold\n","\n","                # Update the best overall performance if it improves\n","                if best_performance_for_features > best_overall_performance:\n","                    best_overall_performance = best_performance_for_features\n","                    best_overall_setup = {\n","                        'features': selected_features,\n","                        'threshold': best_threshold_for_features,\n","                        'performance': best_performance_for_features,\n","                        'feature_selection_method': feature_selector_name,\n","                        'ml_model': ml_model_name\n","                    }\n","\n","            return {\n","                'feature_selection_method': best_overall_setup['feature_selection_method'],\n","                'ml_model': best_overall_setup['ml_model'],\n","                'best_features': best_overall_setup['features'],\n","                'features_length': len(best_overall_setup['features']),\n","                'best_threshold': best_overall_setup['threshold'],\n","                'best_performance': best_overall_setup['performance']\n","            }\n","\n","        # Process combinations of feature selection and prediction models\n","        combinations = [('LASSO', 'XGBoost'), ('ElasticNet', 'XGBoost')]\n","        results_per_combination = [process_combination(fs, ml) for fs, ml in combinations]\n","        best_combination = max(results_per_combination, key=lambda x: x['best_performance'] if x is not None else 0)\n","\n","        return time_point, best_combination\n","\n","    # Process relative time points within the specified range\n","    time_points = np.sort(data['Relative_timepoint'].unique())\n","    results_parallel = Parallel(n_jobs=-1)(delayed(process_time_point)(tp) for tp in time_points)\n","    results = {tp: result for tp, result in results_parallel if result is not None}\n","\n","    return results\n","\n","# Evaluate the model\n","results_relative = evaluate_models(filtered_data)\n","\n","# Print results\n","print(\"Results for Celiac Disease Prediction by Relative Time Point:\")\n","for time_point, res in results_relative.items():\n","    if res is not None:\n","        print(f\"Relative Time Point: {time_point}\")\n","        print(f\"  Feature Selection Method: {res['feature_selection_method']}\")\n","        print(f\"  Machine Learning Model: {res['ml_model']}\")\n","        print(f\"  Best F1 Score: {res['best_performance']}\")\n","        print(f\"  Best Threshold: {res['best_threshold']}\")\n","        print(f\"  Features Used: {res['best_features']}\")\n","        print(f\"  Features Length: {res['features_length']}\")\n","        print(\"-\" * 40)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"elapsed":835,"status":"ok","timestamp":1716337861382,"user":{"displayName":"ZHIQI ZHANG","userId":"11425140851942185431"},"user_tz":240},"id":"Lm_onMZwtMO6","outputId":"65d0c69a-ce52-4932-b2f8-ad6e5058330b"},"outputs":[],"source":["# Create a line chart to show the F1 score for each time point\n","# Sorting the time points\n","sorted_features_time_points = [12, 15]\n","sorted_features_f1_scores = [79, 83]\n","\n","# Create the line chart\n","plt.figure(figsize=(8, 4))\n","\n","# Plot the line with points and set line color, marker size, and style\n","plt.plot(sorted_features_time_points, sorted_features_f1_scores, marker='o', linestyle='-', color='blue', markersize=10)\n","\n","# Add labels to each point\n","for i, score in enumerate(sorted_features_f1_scores):\n","    plt.text(sorted_features_time_points[i], score + 1, f\"{score}\", ha='center', va='bottom', fontsize=14)\n","\n","# Add titles and labels\n","plt.title('F1 Score by Age for CeD Prediction for All Subjects using Combined Abundance Data', fontsize=14, color='blue', pad=20)\n","plt.xlabel('Age (Months)', fontsize=14)\n","plt.ylabel('Average F1 Score', fontsize=14)\n","\n","# Adjust the axis limits\n","plt.xticks(sorted_features_time_points, fontsize=12)\n","plt.ylim(0, 100)\n","plt.yticks(fontsize=12)\n","\n","# Show the plot with tight layout\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a line chart to show the F1 score for each time point\n","# Sorting the time points\n","sorted_features_time_points = [12, 15]\n","sorted_features_f1_scores = [100, 88]\n","\n","# Create the line chart\n","plt.figure(figsize=(8, 4))\n","\n","# Plot the line with points and set line color, marker size, and style\n","plt.plot(sorted_features_time_points, sorted_features_f1_scores, marker='o', linestyle='-', color='blue', markersize=10)\n","\n","# Add labels to each point\n","for i, score in enumerate(sorted_features_f1_scores):\n","    plt.text(sorted_features_time_points[i], score + 1, f\"{score}\", ha='center', va='bottom', fontsize=14)\n","\n","# Add titles and labels\n","plt.title('F1 Score by Age for Early vs. Late Onset Prediction using Combined Abundance Data', fontsize=14, color='blue', pad=20)\n","plt.xlabel('Age (Months)', fontsize=14)\n","plt.ylabel('Average F1 Score', fontsize=14)\n","\n","# Adjust the axis limits\n","plt.xticks(sorted_features_time_points, fontsize=12)\n","plt.ylim(0, 100)\n","plt.yticks(fontsize=12)\n","\n","# Show the plot with tight layout\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a line chart to show the F1 score for each time point\n","# Sorting the time points\n","sorted_features_time_points = [-18, -15, -12, -9, -6, -3, 0]\n","sorted_features_f1_scores = [87, 100, 85, 91, 91, 82, 94]\n","\n","# Create the line chart\n","plt.figure(figsize=(8, 4))\n","\n","# Plot the line with points and set line color, marker size, and style\n","plt.plot(sorted_features_time_points, sorted_features_f1_scores, marker='o', linestyle='-', color='blue', markersize=10)\n","\n","# Add labels to each point\n","for i, score in enumerate(sorted_features_f1_scores):\n","    plt.text(sorted_features_time_points[i], score + 1, f\"{score}\", ha='center', va='bottom', fontsize=14)\n","\n","# Add titles and labels\n","plt.title('F1 Score by Relative Time Point for CeD Prediction using Combined Abundance Data', fontsize=14, color='blue', pad=20)\n","plt.xlabel('Age (Months)', fontsize=14)\n","plt.ylabel('Average F1 Score', fontsize=14)\n","\n","# Adjust the axis limits\n","plt.xticks(sorted_features_time_points, fontsize=12)\n","plt.ylim(0, 100)\n","plt.yticks(fontsize=12)\n","\n","# Show the plot with tight layout\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
